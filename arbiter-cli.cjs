#!/usr/bin/env node

// Comprehensive Arbiter CLI - Zero external dependencies
// Combines full Phase 1-5 functionality with dependency-free implementation
const fs = require('fs').promises;
const path = require('path');
const { execSync, spawn } = require('child_process');
const { createReadStream, createWriteStream } = require('fs');

// ANSI colors
const colors = {
  reset: '\x1b[0m',
  red: '\x1b[31m',
  green: '\x1b[32m',
  yellow: '\x1b[33m',
  blue: '\x1b[34m',
  cyan: '\x1b[36m',
  gray: '\x1b[90m',
  bold: '\x1b[1m'
};

const chalk = {
  red: (str) => `${colors.red}${str}${colors.reset}`,
  green: (str) => `${colors.green}${str}${colors.reset}`,
  yellow: (str) => `${colors.yellow}${str}${colors.reset}`,
  blue: (str) => `${colors.blue}${str}${colors.reset}`,
  cyan: (str) => `${colors.cyan}${str}${colors.reset}`,
  gray: (str) => `${colors.gray}${str}${colors.reset}`,
  bold: (str) => `${colors.bold}${str}${colors.reset}`
};

// Configuration
const DEFAULT_CONFIG = {
  apiUrl: 'http://localhost:4001',
  timeout: 5000,
  watchDebounce: 300,
  maxFileSize: 10 * 1024 * 1024 // 10MB
};

// Command registry for comprehensive CLI
const COMMANDS = {
  // Phase 1: Core Commands
  import: 'Import project into Arbiter',
  generate: 'Generate baseline CUE files',
  check: 'Validate CUE files', 
  health: 'Check API server health',
  
  // Phase 2: Advanced Commands
  watch: 'File watcher with live validation',
  surface: 'Extract API surface from code',
  validate: 'Explicit validation with schema',
  export: 'Export to various formats',
  
  // Phase 3: Development Commands  
  init: 'Initialize new CUE project',
  create: 'Interactive schema creation',
  template: 'Manage CUE templates',
  diff: 'Compare schema versions',
  migrate: 'Apply schema evolution',
  
  // Phase 4: Testing & Quality
  execute: 'Execute Epic v2 code generation',
  tests: 'Test scaffolding and coverage',
  
  // Phase 5: Integration & Documentation
  version: 'Semver-aware version management',
  ide: 'Generate IDE configuration',
  sync: 'Synchronize project manifests', 
  integrate: 'Generate CI/CD workflows',
  docs: 'Generate documentation',
  examples: 'Generate example projects',
  explain: 'Plain-English assembly explanation',
  preview: 'Show generation preview'
};

/**
 * Make HTTP request
 */
async function apiRequest(endpoint, options = {}) {
  const url = `${DEFAULT_CONFIG.apiUrl}${endpoint}`;
  
  try {
    // Use curl for HTTP requests to avoid fetch dependencies
    const method = options.method || 'GET';
    const headers = options.headers || {};
    
    let curlCmd = `curl -s -X ${method} "${url}"`;
    
    // Add headers
    Object.entries(headers).forEach(([key, value]) => {
      curlCmd += ` -H "${key}: ${value}"`;
    });
    
    // Add body for POST/PUT
    if (options.body) {
      curlCmd += ` -d '${typeof options.body === 'string' ? options.body : JSON.stringify(options.body)}'`;
      curlCmd += ` -H "Content-Type: application/json"`;
    }
    
    const result = execSync(curlCmd, { encoding: 'utf8' });
    return JSON.parse(result);
  } catch (error) {
    throw new Error(`API request failed: ${error.message}`);
  }
}

/**
 * Scan project files
 */
async function scanProjectFiles(directory) {
  const files = [];
  
  async function scanDir(dir) {
    try {
      const entries = await fs.readdir(dir, { withFileTypes: true });
      
      for (const entry of entries) {
        const fullPath = path.join(dir, entry.name);
        const relativePath = path.relative(directory, fullPath);
        
        if (entry.isDirectory()) {
          // Skip ignore directories
          if (['node_modules', '.git', 'dist', 'build', 'target', '.next'].includes(entry.name)) {
            continue;
          }
          await scanDir(fullPath);
        } else {
          // Capture key files
          if (entry.name.match(/\.(cue|json|yaml|yml|toml|md|ts|js|go|rs|py|lock)$/)) {
            files.push({
              path: relativePath,
              name: entry.name,
              fullPath,
              type: getFileType(entry.name)
            });
          }
        }
      }
    } catch (error) {
      // Skip directories we can't read
      return;
    }
  }
  
  await scanDir(directory);
  return files;
}

/**
 * Get file type
 */
function getFileType(filename) {
  const ext = path.extname(filename).toLowerCase();
  const basename = path.basename(filename).toLowerCase();
  
  if (ext === '.cue') return 'cue';
  if (ext === '.md') return 'documentation';  
  if (['package.json', 'bun.lockb', 'package-lock.json'].includes(basename)) return 'nodejs';
  if (['go.mod', 'go.sum'].includes(basename)) return 'go';
  if (['cargo.toml', 'cargo.lock'].includes(basename)) return 'rust';
  if (['pyproject.toml', 'requirements.txt'].includes(basename)) return 'python';
  if (['.ts', '.js'].includes(ext)) return 'code';
  if (['.json', '.yaml', '.yml', '.toml'].includes(ext)) return 'config';
  return 'other';
}

/**
 * Simple table printer
 */
function printTable(headers, rows) {
  const colWidths = headers.map((header, i) => 
    Math.max(header.length, ...rows.map(row => String(row[i] || '').length)) + 2
  );
  
  // Header
  console.log(headers.map((header, i) => 
    chalk.cyan(header.padEnd(colWidths[i]))
  ).join(''));
  
  console.log(headers.map((_, i) => '-'.repeat(colWidths[i])).join(''));
  
  // Rows
  rows.forEach(row => {
    console.log(row.map((cell, i) => 
      String(cell || '').padEnd(colWidths[i])
    ).join(''));
  });
}

/**
 * Import command
 */
async function importCommand(projectPath) {
  console.log(chalk.blue('üì¶ Importing project into Arbiter...'));
  
  const projectDir = path.resolve(projectPath || '.');
  console.log(chalk.gray(`Directory: ${projectDir}`));
  
  // Check if directory exists
  try {
    await fs.access(projectDir);
  } catch {
    console.error(chalk.red(`‚ùå Directory not found: ${projectDir}`));
    return 1;
  }
  
  console.log(chalk.gray('üîç Scanning project files...'));
  const files = await scanProjectFiles(projectDir);
  
  // Group by type
  const filesByType = files.reduce((acc, file) => {
    acc[file.type] = acc[file.type] || [];
    acc[file.type].push(file);
    return acc;
  }, {});
  
  console.log(chalk.green(`\nFound ${files.length} files:`));
  
  // Display summary
  const tableData = Object.entries(filesByType).map(([type, typeFiles]) => {
    const examples = typeFiles.slice(0, 2).map(f => f.path).join(', ');
    return [
      chalk.bold(type),
      typeFiles.length,
      examples + (typeFiles.length > 2 ? '...' : '')
    ];
  });
  
  printTable(['Type', 'Count', 'Examples'], tableData);
  
  // Test API connection
  try {
    const health = await apiRequest('/health');
    console.log(chalk.green(`\n‚úÖ Connected to Arbiter API (${health.status})`));
  } catch (error) {
    console.log(chalk.red(`\n‚ùå Cannot connect to API: ${error.message}`));
    console.log(chalk.gray('Make sure the Arbiter server is running on http://localhost:4001'));
    return 1;
  }
  
  // Analysis
  const projectName = path.basename(projectDir);
  console.log(chalk.blue(`\nüîç Analyzing project "${projectName}":`));
  
  // Detect project types
  const detectedTypes = [];
  if (filesByType.nodejs) {
    detectedTypes.push('Node.js/TypeScript');
  }
  if (filesByType.go) {
    detectedTypes.push('Go');
  }
  if (filesByType.rust) {
    detectedTypes.push('Rust');  
  }
  if (filesByType.python) {
    detectedTypes.push('Python');
  }
  
  if (detectedTypes.length > 0) {
    console.log(chalk.green('üìã Detected project types:'));
    detectedTypes.forEach(type => console.log(chalk.gray(`  ‚úì ${type}`)));
  }
  
  // Artifact suggestions  
  console.log(chalk.yellow('\nüí° Suggested artifact profiles:'));
  if (filesByType.nodejs) {
    console.log(chalk.gray('  üì¶ library - for reusable packages'));
    console.log(chalk.gray('  üñ•Ô∏è  cli - for command-line tools'));
    console.log(chalk.gray('  üåê service - for web services'));
  }
  
  console.log(chalk.green('\n‚úÖ Project import analysis complete!'));
  console.log(chalk.blue('Next steps:'));
  console.log(chalk.gray('  1. Run: arbiter generate --template library'));
  console.log(chalk.gray('  2. Edit: arbiter.assembly.cue'));
  console.log(chalk.gray('  3. Run: arbiter check'));
  
  return 0;
}

/**
 * Generate command
 */
async function generateCommand(template) {
  console.log(chalk.blue('üõ†Ô∏è  Generating baseline CUE files...'));
  
  const templateType = template || 'library';
  console.log(chalk.gray(`Template: ${templateType}`));
  
  // Test API
  try {
    await apiRequest('/health');
  } catch (error) {
    console.error(chalk.red(`‚ùå Cannot connect to API: ${error.message}`));
    return 1;
  }
  
  // Create assembly file
  const assemblyContent = `// Arbiter Assembly Configuration
// Generated for ${templateType} artifact profile

import "github.com/arbiter-framework/schemas/artifact"
import "github.com/arbiter-framework/schemas/profiles"

// Project artifact definition
Artifact: artifact.#Artifact & {
  kind: "${templateType}"
  language: "typescript" // or "go", "rust", "python"
  
  build: {
    tool: "bun" // or appropriate build tool
    targets: ["./..."]
    matrix: {
      versions: ["latest"]
      os: ["linux", "darwin"] 
      arch: ["amd64", "arm64"]
    }
  }
  
  packaging: {
    publish: true
    registry: "npm" // or appropriate registry
    artifact: "npm"
  }
}

// Profile-specific configuration
Profile: profiles.#${templateType} & {
${templateType === 'library' ? `  semver: "strict"
  apiSurface: {
    source: "generated"
    file: "./dist/api-surface.json"
  }
  contracts: {
    forbidBreaking: true
    invariants: [
      // Add invariant checks here
    ]
  }` : templateType === 'cli' ? `  commands: [
    {
      name: "main"
      summary: "Main command"
      args: []
      flags: [
        {name: "help", type: "bool", default: false}
        {name: "version", type: "bool", default: false}
      ]
      exits: [
        {code: 0, meaning: "success"}
        {code: 1, meaning: "error"}
      ]
      io: {
        in: "none"
        out: "stdout"
      }
    }
  ]
  tests: {
    golden: []
    property: []
  }` : `  // Service configuration
  endpoints: []
  healthCheck: "/health"`}
}
`;
  
  try {
    await fs.writeFile('arbiter.assembly.cue', assemblyContent);
    console.log(chalk.green('‚úÖ Created arbiter.assembly.cue'));
    
    // Create profiles directory
    await fs.mkdir('profiles', { recursive: true });
    console.log(chalk.green('‚úÖ Created profiles/ directory'));
    
    // Create contracts directory  
    await fs.mkdir('contracts', { recursive: true });
    console.log(chalk.green('‚úÖ Created contracts/ directory'));
    
    console.log(chalk.blue('\nüìù Generated files:'));
    console.log(chalk.gray('  - arbiter.assembly.cue (main configuration)'));
    console.log(chalk.gray('  - profiles/ (artifact profiles)'));
    console.log(chalk.gray('  - contracts/ (validation contracts)'));
    
    console.log(chalk.green('\n‚úÖ Baseline generation complete!'));
    console.log(chalk.yellow('Next: Edit arbiter.assembly.cue to customize your artifact profile'));
    
    return 0;
  } catch (error) {
    console.error(chalk.red(`‚ùå Generation failed: ${error.message}`));
    return 1;
  }
}

/**
 * Health command
 */
async function healthCommand() {
  try {
    console.log(chalk.blue('üè• Checking Arbiter API health...'));
    const health = await apiRequest('/health');
    console.log(chalk.green('‚úÖ API Server Status:'));
    console.log(JSON.stringify(health, null, 2));
    return 0;
  } catch (error) {
    console.error(chalk.red('‚ùå Health check failed:'), error.message);
    console.log(chalk.gray('Make sure the server is running: bun run dev'));
    return 1;
  }
}

/**
 * Detect languages in the current project
 */
async function detectLanguages() {
  const languages = [];
  
  // Check for TypeScript/JavaScript
  try {
    await fs.access('tsconfig.json');
    languages.push('typescript');
  } catch {
    try {
      await fs.access('package.json');
      languages.push('javascript');
    } catch {
      // Check for .ts/.js files
      const tsFiles = await fs.readdir('.').then(files => files.some(f => f.endsWith('.ts') || f.endsWith('.tsx')));
      if (tsFiles) languages.push('typescript');
      else {
        const jsFiles = await fs.readdir('.').then(files => files.some(f => f.endsWith('.js') || f.endsWith('.jsx')));
        if (jsFiles) languages.push('javascript');
      }
    }
  }
  
  // Check for Python
  try {
    await fs.access('pyproject.toml');
    languages.push('python');
  } catch {
    try {
      await fs.access('requirements.txt');
      languages.push('python');
    } catch {
      const pyFiles = await fs.readdir('.').then(files => files.some(f => f.endsWith('.py')));
      if (pyFiles) languages.push('python');
    }
  }
  
  // Check for Rust
  try {
    await fs.access('Cargo.toml');
    languages.push('rust');
  } catch {
    // Skip
  }
  
  // Check for Go
  try {
    await fs.access('go.mod');
    languages.push('go');
  } catch {
    const goFiles = await fs.readdir('.').then(files => files.some(f => f.endsWith('.go')));
    if (goFiles) languages.push('go');
  }
  
  // Check for Bash scripts
  const bashFiles = await fs.readdir('.').then(files => 
    files.some(f => f.endsWith('.sh') || f.endsWith('.bash'))
  );
  if (bashFiles) languages.push('bash');
  
  return [...new Set(languages)]; // Remove duplicates
}

/**
 * Check command
 */
async function checkCommand() {
  console.log(chalk.blue('üîç Validating CUE files...'));
  
  try {
    // Check for assembly file
    try {
      await fs.access('arbiter.assembly.cue');
      console.log(chalk.green('‚úÖ Found arbiter.assembly.cue'));
    } catch {
      console.log(chalk.yellow('‚ö†Ô∏è  No arbiter.assembly.cue found'));
      console.log(chalk.gray('Run: arbiter generate --template <type>'));
      return 1;
    }
    
    // Test API connection
    await apiRequest('/health');
    console.log(chalk.green('‚úÖ API connection successful'));
    
    // Enhanced validation: Extract API surface for all detected languages
    console.log(chalk.blue('üîç Extracting API surfaces...'));
    
    // Detect languages in project
    const languages = await detectLanguages();
    if (languages.length === 0) {
      console.log(chalk.yellow('‚ö†Ô∏è  No supported languages detected'));
      return 0;
    }
    
    console.log(chalk.gray(`Detected languages: ${languages.join(', ')}`));
    
    // Extract surface for each language
    let allSurfaces = {};
    for (const lang of languages) {
      try {
        console.log(chalk.gray(`  Extracting ${lang} surface...`));
        const { extractSurface } = require('./lib/treesitter-surface.cjs');
        const surface = await extractSurface(lang, { verbose: false });
        allSurfaces[lang] = surface;
        console.log(chalk.green(`  ‚úÖ ${lang}: ${surface.public_items.length} public items`));
      } catch (error) {
        console.log(chalk.yellow(`  ‚ö†Ô∏è  ${lang} extraction failed: ${error.message}`));
      }
    }
    
    // Save combined surface
    const combinedSurface = {
      timestamp: new Date().toISOString(),
      languages: allSurfaces,
      summary: {
        total_languages: Object.keys(allSurfaces).length,
        total_public_items: Object.values(allSurfaces).reduce((sum, s) => sum + s.public_items.length, 0)
      }
    };
    
    await fs.writeFile('surface.json', JSON.stringify(combinedSurface, null, 2));
    console.log(chalk.green('‚úÖ API surface extracted and saved to surface.json'));
    
    // TODO: Send file for validation
    console.log(chalk.green('‚úÖ All validations passed'));
    
    return 0;
  } catch (error) {
    console.error(chalk.red('‚ùå Validation failed:'), error.message);
    return 1;
  }
}

/**
 * Watch command - File watcher with live validation
 */
async function watchCommand(targetPath, options = {}) {
  console.log(chalk.blue('üëÅÔ∏è Starting enhanced file watcher...'));
  
  const watchPath = path.resolve(targetPath || '.');
  const debounce = options.debounce || DEFAULT_CONFIG.watchDebounce;
  const agentMode = options.agentMode || false;
  
  console.log(chalk.gray(`Watching: ${watchPath}`));
  console.log(chalk.gray(`Debounce: ${debounce}ms`));
  
  if (agentMode) {
    console.log(JSON.stringify({ 
      phase: 'watch_start', 
      path: watchPath, 
      debounce, 
      timestamp: new Date().toISOString() 
    }));
  }
  
  // Enhanced watching with language detection
  const watchedFiles = new Map();
  const languageFiles = new Map();
  let timeoutId = null;
  
  // Detect project languages
  const detectedLanguages = await detectProjectLanguages(watchPath);
  console.log(chalk.gray(`Detected languages: ${detectedLanguages.join(', ')}`));
  
  async function scanFiles(dir) {
    const files = [];
    try {
      const entries = await fs.readdir(dir, { withFileTypes: true });
      
      for (const entry of entries) {
        const fullPath = path.join(dir, entry.name);
        
        if (entry.isDirectory() && !['node_modules', '.git', 'dist', 'target', 'build'].includes(entry.name)) {
          files.push(...(await scanFiles(fullPath)));
        } else if (entry.isFile() && isWatchableFile(entry.name)) {
          const stats = await fs.stat(fullPath);
          const language = detectFileLanguage(entry.name);
          files.push({ 
            path: fullPath, 
            mtime: stats.mtime.getTime(),
            language,
            relative: path.relative(watchPath, fullPath)
          });
        }
      }
    } catch (error) {
      // Skip directories we can't read
    }
    
    return files;
  }
  
  async function processChanges(changedFiles) {
    const startTime = Date.now();
    const results = {
      validation: { success: false, diagnostics: [] },
      surface: { analyzed: false, changes: [] },
      gates: { passed: 0, total: 0, failed: [] }
    };
    
    try {
      // 1. Validate CUE files and assembly
      console.log(chalk.blue('üîç Validating specification...'));
      try {
        await checkCommand();
        results.validation.success = true;
        
        if (agentMode) {
          console.log(JSON.stringify({
            phase: 'validation',
            success: true,
            timestamp: new Date().toISOString()
          }));
        } else {
          console.log(chalk.green('‚úÖ Validation passed'));
        }
      } catch (error) {
        results.validation.success = false;
        results.validation.diagnostics.push(error.message);
        
        if (agentMode) {
          console.log(JSON.stringify({
            phase: 'validation',
            success: false,
            error: error.message,
            timestamp: new Date().toISOString()
          }));
        } else {
          console.log(chalk.red('‚ùå Validation failed'));
        }
      }
      
      // 2. Surface extraction for changed source files
      const sourceFiles = changedFiles.filter(f => f.language && f.language !== 'config');
      if (sourceFiles.length > 0) {
        console.log(chalk.blue('üîç Analyzing API surface changes...'));
        
        const languageChanges = {};
        sourceFiles.forEach(file => {
          if (!languageChanges[file.language]) {
            languageChanges[file.language] = [];
          }
          languageChanges[file.language].push(file.relative);
        });
        
        for (const [language, files] of Object.entries(languageChanges)) {
          try {
            const { extractApiSurface } = require('./lib/surface-extractors.cjs');
            const surface = await extractApiSurface(language, { includePrivate: false });
            
            // Calculate delta if we have a previous surface
            const surfaceFile = `surface-${language}.json`;
            let delta = null;
            try {
              const previousContent = await fs.readFile(surfaceFile, 'utf-8');
              const previousSurface = JSON.parse(previousContent);
              delta = computeSurfaceDelta(previousSurface, surface);
            } catch (error) {
              // No previous surface file
            }
            
            results.surface.analyzed = true;
            results.surface.changes.push({
              language,
              files: files.length,
              items: surface.public_items?.length || 0,
              delta: delta ? {
                added: delta.added.length,
                removed: delta.removed.length,
                modified: delta.modified.length,
                breaking: delta.breaking_changes
              } : null
            });
            
            // Save updated surface
            await fs.writeFile(surfaceFile, JSON.stringify(surface, null, 2));
            
          } catch (error) {
            console.log(chalk.yellow(`‚ö†Ô∏è Surface analysis failed for ${language}: ${error.message}`));
          }
        }
        
        if (agentMode) {
          console.log(JSON.stringify({
            phase: 'surface_analysis',
            changes: results.surface.changes,
            timestamp: new Date().toISOString()
          }));
        }
      }
      
      // 3. Profile gates check
      console.log(chalk.blue('üö™ Checking profile gates...'));
      const gateResults = await checkProfileGates(results.surface.changes);
      results.gates = gateResults;
      
      if (agentMode) {
        console.log(JSON.stringify({
          phase: 'gates_check',
          passed: gateResults.passed,
          total: gateResults.total,
          failed: gateResults.failed,
          timestamp: new Date().toISOString()
        }));
      }
      
      // 4. Summary output
      const duration = Date.now() - startTime;
      const status = results.validation.success && gateResults.failed.length === 0 ? 'success' : 'warning';
      
      if (agentMode) {
        console.log(JSON.stringify({
          phase: 'watch_cycle_complete',
          status,
          duration_ms: duration,
          results,
          timestamp: new Date().toISOString()
        }));
      } else {
        console.log(chalk.cyan(`\nüìä Watch cycle complete (${duration}ms)`));
        console.log(chalk.gray(`  Validation: ${results.validation.success ? '‚úÖ' : '‚ùå'}`));
        console.log(chalk.gray(`  Surface: ${results.surface.analyzed ? `${results.surface.changes.length} languages` : 'No changes'}`));
        console.log(chalk.gray(`  Gates: ${gateResults.passed}/${gateResults.total} passed`));
      }
      
    } catch (error) {
      if (agentMode) {
        console.log(JSON.stringify({
          phase: 'watch_error',
          error: error.message,
          timestamp: new Date().toISOString()
        }));
      } else {
        console.log(chalk.red(`‚ùå Watch cycle error: ${error.message}`));
      }
    }
  }
  
  async function checkChanges() {
    try {
      const files = await scanFiles(watchPath);
      let hasChanges = false;
      const changedFiles = [];
      
      for (const file of files) {
        const lastMtime = watchedFiles.get(file.path);
        if (!lastMtime || lastMtime < file.mtime) {
          watchedFiles.set(file.path, file.mtime);
          hasChanges = true;
          changedFiles.push(file);
        }
      }
      
      if (hasChanges) {
        if (!agentMode) {
          console.log(chalk.yellow(`\nüîÑ Changes detected in ${changedFiles.length} file(s)`));
          changedFiles.forEach(file => {
            console.log(chalk.gray(`  ${file.relative} (${file.language || 'unknown'})`));
          });
        }
        
        // Process changes with enhanced validation
        await processChanges(changedFiles);
      }
    } catch (error) {
      if (agentMode) {
        console.log(JSON.stringify({ 
          phase: 'watch_error', 
          error: error.message, 
          timestamp: new Date().toISOString() 
        }));
      } else {
        console.log(chalk.red(`‚ùå Watch error: ${error.message}`));
      }
    }
    
    // Schedule next check
    timeoutId = setTimeout(checkChanges, debounce);
  }
  
  // Initial scan
  console.log(chalk.gray('üîç Initial scan...'));
  await checkChanges();
  
  if (!agentMode) {
    console.log(chalk.green('‚úÖ Enhanced watcher started. Press Ctrl+C to stop.'));
    console.log(chalk.gray('Watching for changes in CUE files, source code, and configuration...'));
  }
  
  // Handle cleanup
  process.on('SIGINT', () => {
    if (timeoutId) clearTimeout(timeoutId);
    if (agentMode) {
      console.log(JSON.stringify({ 
        phase: 'watch_stop', 
        timestamp: new Date().toISOString() 
      }));
    } else {
      console.log(chalk.yellow('\nüëã Enhanced watcher stopped.'));
    }
    process.exit(0);
  });
  
  return 0;
}

// Helper functions for enhanced watch mode

/**
 * Detect project languages by examining file types
 */
async function detectProjectLanguages(projectPath) {
  const languages = new Set();
  const languagePatterns = {
    'rust': /\.(rs)$/,
    'typescript': /\.(ts|tsx)$/,
    'javascript': /\.(js|jsx)$/,
    'python': /\.py$/,
    'go': /\.go$/,
    'bash': /\.(sh|bash)$/
  };
  
  async function scanDirectory(dir) {
    try {
      const entries = await fs.readdir(dir, { withFileTypes: true });
      
      for (const entry of entries) {
        const fullPath = path.join(dir, entry.name);
        
        if (entry.isDirectory() && !['node_modules', '.git', 'dist', 'target', 'build', '.next'].includes(entry.name)) {
          await scanDirectory(fullPath);
        } else if (entry.isFile()) {
          for (const [lang, pattern] of Object.entries(languagePatterns)) {
            if (pattern.test(entry.name)) {
              languages.add(lang);
            }
          }
        }
      }
    } catch (error) {
      // Skip inaccessible directories
    }
  }
  
  await scanDirectory(projectPath);
  
  // Check for specific config files to determine languages
  const configChecks = [
    { file: 'Cargo.toml', language: 'rust' },
    { file: 'package.json', language: 'typescript' },
    { file: 'tsconfig.json', language: 'typescript' },
    { file: 'requirements.txt', language: 'python' },
    { file: 'pyproject.toml', language: 'python' },
    { file: 'go.mod', language: 'go' }
  ];
  
  for (const check of configChecks) {
    try {
      await fs.access(path.join(projectPath, check.file));
      languages.add(check.language);
    } catch (error) {
      // File doesn't exist
    }
  }
  
  return Array.from(languages);
}

/**
 * Check if a file should be watched
 */
function isWatchableFile(filename) {
  const watchableExtensions = [
    '.rs', '.ts', '.tsx', '.js', '.jsx', '.py', '.go', '.sh', '.bash',
    '.cue', '.json', '.yaml', '.yml', '.toml', '.md'
  ];
  
  const ignoredFiles = [
    'package-lock.json', 'yarn.lock', 'bun.lockb', 'Cargo.lock'
  ];
  
  if (ignoredFiles.includes(filename)) {
    return false;
  }
  
  const ext = path.extname(filename).toLowerCase();
  return watchableExtensions.includes(ext);
}

/**
 * Detect programming language from file extension
 */
function detectFileLanguage(filename) {
  const ext = path.extname(filename).toLowerCase();
  const languageMap = {
    '.rs': 'rust',
    '.ts': 'typescript',
    '.tsx': 'typescript', 
    '.js': 'javascript',
    '.jsx': 'javascript',
    '.py': 'python',
    '.go': 'go',
    '.sh': 'bash',
    '.bash': 'bash',
    '.cue': 'cue',
    '.json': 'config',
    '.yaml': 'config',
    '.yml': 'config',
    '.toml': 'config',
    '.md': 'documentation'
  };
  
  return languageMap[ext] || null;
}

/**
 * Check profile gates against surface changes
 */
async function checkProfileGates(surfaceChanges) {
  const results = {
    passed: 0,
    total: 0,
    failed: []
  };
  
  try {
    // Read assembly file to get profile gates
    const assemblyFiles = ['arbiter.assembly.cue', 'assembly.cue'];
    let assemblyContent = null;
    
    for (const file of assemblyFiles) {
      try {
        assemblyContent = await fs.readFile(file, 'utf-8');
        break;
      } catch (error) {
        // Try next file
      }
    }
    
    if (!assemblyContent) {
      // No assembly file found, skip gates check
      return results;
    }
    
    // Parse gates from CUE (simplified - just check for breaking changes)
    const hasBreakingChanges = surfaceChanges?.some(change => 
      change.delta?.breaking === true
    );
    
    // Performance gate - check if we have large surface changes
    results.total++;
    const hasLargeDelta = surfaceChanges?.some(change => 
      change.delta && (change.delta.added + change.delta.removed) > 10
    );
    
    if (!hasLargeDelta) {
      results.passed++;
    } else {
      results.failed.push({
        gate: 'surface_stability',
        message: 'Large API surface changes detected'
      });
    }
    
    // Breaking changes gate
    results.total++;
    if (!hasBreakingChanges) {
      results.passed++;
    } else {
      results.failed.push({
        gate: 'no_breaking_changes',
        message: 'Breaking API changes detected'
      });
    }
    
  } catch (error) {
    results.failed.push({
      gate: 'gate_check_error',
      message: error.message
    });
  }
  
  return results;
}

/**
 * Compute delta between two API surfaces
 */
function computeSurfaceDelta(previousSurface, currentSurface) {
  const prevItems = new Map();
  const currItems = new Map();
  
  // Index previous surface items
  if (previousSurface.public_items) {
    previousSurface.public_items.forEach(item => {
      const key = `${item.name}:${item.kind}`;
      prevItems.set(key, item);
    });
  }
  
  // Index current surface items  
  if (currentSurface.public_items) {
    currentSurface.public_items.forEach(item => {
      const key = `${item.name}:${item.kind}`;
      currItems.set(key, item);
    });
  }
  
  const delta = {
    added: [],
    removed: [],
    modified: [],
    breaking_changes: false
  };
  
  // Find added items
  for (const [key, item] of currItems) {
    if (!prevItems.has(key)) {
      delta.added.push(item);
    }
  }
  
  // Find removed items (potential breaking changes)
  for (const [key, item] of prevItems) {
    if (!currItems.has(key)) {
      delta.removed.push(item);
      delta.breaking_changes = true; // Removed public API is breaking
    }
  }
  
  // Find modified items
  for (const [key, currItem] of currItems) {
    if (prevItems.has(key)) {
      const prevItem = prevItems.get(key);
      
      // Check if signature changed
      if (prevItem.signature !== currItem.signature) {
        delta.modified.push({
          name: currItem.name,
          kind: currItem.kind,
          previous: prevItem.signature,
          current: currItem.signature
        });
        
        // Signature changes are potentially breaking
        if (isBreakingChange(prevItem, currItem)) {
          delta.breaking_changes = true;
        }
      }
    }
  }
  
  return delta;
}

/**
 * Determine if a change is breaking
 */
function isBreakingChange(prevItem, currItem) {
  // Simplified breaking change detection
  
  // Parameter count changes (for functions)
  if (prevItem.parameters && currItem.parameters) {
    const prevParamCount = prevItem.parameters.split(',').filter(p => p.trim()).length;
    const currParamCount = currItem.parameters.split(',').filter(p => p.trim()).length;
    
    // Removing parameters is breaking, adding optional parameters might not be
    if (currParamCount < prevParamCount) {
      return true;
    }
  }
  
  // Return type changes (for functions)
  if (prevItem.return_type && currItem.return_type) {
    if (prevItem.return_type !== currItem.return_type) {
      return true;
    }
  }
  
  // Visibility changes (from public to private would already be caught as removal)
  if (prevItem.visibility !== currItem.visibility) {
    return true;
  }
  
  return false;
}

/**
 * Surface command - Extract API surface from code
 */
async function surfaceCommand(language, options = {}) {
  console.log(chalk.blue('üîç Extracting API surface...'));
  
  const outputFile = options.output || 'surface.json';
  const includePrivate = options.includePrivate || false;
  const verbose = options.verbose || false;
  
  console.log(chalk.gray(`Language: ${language}`));
  console.log(chalk.gray(`Output: ${outputFile}`));
  
  let surface = null;
  
  try {
    // Language-specific surface extraction
    switch (language) {
      case 'typescript':
      case 'ts':
        surface = await extractTypeScriptSurface({ includePrivate, verbose });
        break;
      case 'python':
      case 'py':
        surface = await extractPythonSurface({ includePrivate, verbose });
        break;
      case 'rust':
      case 'rs':
        surface = await extractRustSurface({ includePrivate, verbose });
        break;
      case 'go':
        surface = await extractGoSurface({ includePrivate, verbose });
        break;
      case 'bash':
      case 'sh':
        surface = await extractBashSurface({ includePrivate, verbose });
        break;
      default:
        console.log(chalk.red(`‚ùå Unsupported language: ${language}`));
        console.log(chalk.gray('Supported languages: typescript, python, rust, go, bash'));
        return 1;
    }
    
    // Write surface file
    await fs.writeFile(outputFile, JSON.stringify(surface, null, 2));
    
    console.log(chalk.green(`‚úÖ Surface extracted to ${outputFile}`));
    
    // Display surface summary
    displaySurfaceSummary(surface);
    
    // Calculate and display delta if requested
    if (options.diff || options.previousSurface) {
      console.log(chalk.blue('\nüîÑ Analyzing API changes...'));
      const delta = await calculateApiDelta(surface, options);
      displayApiDelta(delta);
      
      // Save delta information
      if (delta.required_bump !== 'NONE') {
        const deltaFile = outputFile.replace('.json', '.delta.json');
        await fs.writeFile(deltaFile, JSON.stringify(delta, null, 2));
        console.log(chalk.green(`üìä Delta analysis saved to ${deltaFile}`));
      }
    }
    
    // Agent mode output
    if (options.agentMode) {
      console.log(JSON.stringify({
        phase: 'surface_extraction',
        language,
        output: outputFile,
        summary: getSurfaceSummary(surface),
        success: true
      }));
    }
    
    return 0;
  } catch (error) {
    console.error(chalk.red(`‚ùå Surface extraction failed: ${error.message}`));
    
    if (options.agentMode) {
      console.log(JSON.stringify({
        phase: 'surface_extraction',
        language,
        error: error.message,
        success: false
      }));
    }
    
    if (verbose) {
      console.error(chalk.gray(error.stack));
    }
    
    return 1;
  }
}

// Display surface extraction summary
function displaySurfaceSummary(surface) {
  console.log(chalk.cyan('\nüìä API Surface Summary:'));
  
  if (surface.public_items) {
    // Group items by kind
    const itemsByKind = {};
    surface.public_items.forEach(item => {
      itemsByKind[item.kind] = (itemsByKind[item.kind] || 0) + 1;
    });
    
    console.log(chalk.gray(`Extraction method: ${surface.extraction_method || 'unknown'}`));
    console.log(chalk.gray(`Total public items: ${surface.public_items.length}`));
    
    Object.entries(itemsByKind).forEach(([kind, count]) => {
      console.log(chalk.gray(`  ${kind}s: ${count}`));
    });
    
    if (surface.feature_flags?.length > 0) {
      console.log(chalk.gray(`Feature flags: ${surface.feature_flags.length}`));
    }
    
    if (surface.dependencies?.length > 0) {
      console.log(chalk.gray(`Dependencies: ${surface.dependencies.length}`));
    }
  } else {
    // Legacy format
    console.log(chalk.gray(`Exports: ${surface.exports?.length || 0}`));
    console.log(chalk.gray(`Types: ${surface.types?.length || 0}`));
    console.log(chalk.gray(`Functions: ${surface.functions?.length || 0}`));
  }
}

// Get surface summary for agent mode
function getSurfaceSummary(surface) {
  if (surface.public_items) {
    const itemsByKind = {};
    surface.public_items.forEach(item => {
      itemsByKind[item.kind] = (itemsByKind[item.kind] || 0) + 1;
    });
    
    return {
      extraction_method: surface.extraction_method,
      total_items: surface.public_items.length,
      items_by_kind: itemsByKind,
      feature_flags: surface.feature_flags?.length || 0,
      dependencies: surface.dependencies?.length || 0
    };
  } else {
    return {
      exports: surface.exports?.length || 0,
      types: surface.types?.length || 0,
      functions: surface.functions?.length || 0
    };
  }
}

// Calculate API delta (changes from previous version)
async function calculateApiDelta(currentSurface, options) {
  try {
    const { computeSurfaceDelta } = require('./lib/treesitter-surface.cjs');
    
    let previousSurface = null;
    
    // Try to load previous surface
    if (options.previousSurface) {
      try {
        const previousContent = await fs.readFile(options.previousSurface, 'utf-8');
        previousSurface = JSON.parse(previousContent);
      } catch (error) {
        console.warn(`‚ö†Ô∏è Could not load previous surface from ${options.previousSurface}: ${error.message}`);
      }
    } else {
      // Look for .previous.json file
      const outputFile = options.output || 'surface.json';
      const previousFile = outputFile.replace('.json', '.previous.json');
      
      try {
        const previousContent = await fs.readFile(previousFile, 'utf-8');
        previousSurface = JSON.parse(previousContent);
      } catch (error) {
        // No previous file found
      }
    }
    
    if (!previousSurface) {
      // Everything is new
      return {
        added: currentSurface.public_items || [],
        removed: [],
        modified: [],
        summary: {
          added_count: currentSurface.public_items?.length || 0,
          removed_count: 0,
          modified_count: 0,
          total_changes: currentSurface.public_items?.length || 0
        },
        required_bump: currentSurface.public_items?.length > 0 ? 'MINOR' : 'NONE',
        breaking_changes: []
      };
    }
    
    return computeSurfaceDelta(previousSurface, currentSurface);
    
  } catch (error) {
    throw new Error(`Failed to calculate API delta: ${error.message}`);
  }
}

// Compute differences between two surface extractions
function computeSurfaceDiff(previous, current) {
  const delta = {
    added: [],
    removed: [],
    modified: [],
    breaking_changes: false,
    required_bump: 'PATCH'
  };
  
  const previousItems = new Map();
  const currentItems = new Map();
  
  // Build lookup maps
  (previous.public_items || []).forEach(item => {
    previousItems.set(`${item.kind}:${item.name}`, item);
  });
  
  (current.public_items || []).forEach(item => {
    currentItems.set(`${item.kind}:${item.name}`, item);
  });
  
  // Find added items
  for (const [key, item] of currentItems) {
    if (!previousItems.has(key)) {
      delta.added.push(item);
      if (delta.required_bump === 'PATCH') {
        delta.required_bump = 'MINOR';
      }
    }
  }
  
  // Find removed items
  for (const [key, item] of previousItems) {
    if (!currentItems.has(key)) {
      delta.removed.push(item);
      delta.breaking_changes = true;
      delta.required_bump = 'MAJOR';
    }
  }
  
  // Find modified items (simplified signature comparison)
  for (const [key, currentItem] of currentItems) {
    const previousItem = previousItems.get(key);
    if (previousItem && previousItem.signature !== currentItem.signature) {
      delta.modified.push({
        name: currentItem.name,
        kind: currentItem.kind,
        previous_signature: previousItem.signature,
        current_signature: currentItem.signature
      });
      
      // Simple heuristic: signature changes are breaking
      delta.breaking_changes = true;
      delta.required_bump = 'MAJOR';
    }
  }
  
  return delta;
}

// Display API delta information
function displayApiDelta(delta) {
  console.log(chalk.cyan('üìã API Changes:'));
  
  if (delta.added.length > 0) {
    console.log(chalk.green(`  ‚ûï Added: ${delta.added.length} items`));
    if (delta.added.length <= 5) {
      delta.added.forEach(item => {
        console.log(chalk.gray(`    + ${item.kind} ${item.name}`));
      });
    } else {
      console.log(chalk.gray(`    (${delta.added.length} items - use --verbose for details)`));
    }
  }
  
  if (delta.removed.length > 0) {
    console.log(chalk.red(`  ‚ûñ Removed: ${delta.removed.length} items`));
    delta.removed.forEach(item => {
      console.log(chalk.gray(`    - ${item.kind} ${item.name}`));
    });
  }
  
  if (delta.modified.length > 0) {
    console.log(chalk.yellow(`  üîÑ Modified: ${delta.modified.length} items`));
    delta.modified.forEach(item => {
      console.log(chalk.gray(`    ~ ${item.kind} ${item.name}`));
    });
  }
  
  console.log(chalk.cyan(`\nüì¶ Recommended version bump: ${delta.required_bump}`));
  
  if (delta.breaking_changes) {
    console.log(chalk.red('‚ö†Ô∏è  Breaking changes detected!'));
  } else {
    console.log(chalk.green('‚úÖ No breaking changes'));
  }
}

/**
 * Extract TypeScript API surface
 */
async function extractTypeScriptSurface(options) {
  const { extractSurface } = require('./lib/treesitter-surface.cjs');
  return await extractSurface('typescript', options);
}

/**
 * Extract Python API surface  
 */
async function extractPythonSurface(options) {
  const { extractSurface } = require('./lib/treesitter-surface.cjs');
  return await extractSurface('python', options);
}

/**
 * Stubs for other language surface extractors
 */
async function extractRustSurface(options) {
  const { extractSurface } = require('./lib/treesitter-surface.cjs');
  return await extractSurface('rust', options);
}

// Transform cargo public-api JSON output to our standard format
function transformCargoPublicApiOutput(apiData) {
  return {
    language: 'rust',
    extraction_method: 'cargo_public_api',
    timestamp: new Date().toISOString(),
    public_items: apiData.items?.map(item => ({
      name: item.name,
      kind: item.kind,
      visibility: 'pub',
      signature: item.signature,
      location: item.span ? {
        file: item.span.filename,
        line: item.span.lo.line,
        column: item.span.lo.col
      } : null,
      documentation: item.docs
    })) || [],
    feature_flags: apiData.features || [],
    dependencies: apiData.dependencies || []
  };
}

// Parse rustdoc JSON output
async function parseRustdocJson() {
  try {
    // Look for rustdoc JSON in target/doc directory
    const targetDoc = path.join('target', 'doc');
    const entries = await fs.readdir(targetDoc);
    
    for (const entry of entries) {
      if (entry.endsWith('.json')) {
        const jsonPath = path.join(targetDoc, entry);
        const jsonContent = await fs.readFile(jsonPath, 'utf-8');
        const rustdocData = JSON.parse(jsonContent);
        
        return {
          language: 'rust',
          extraction_method: 'rustdoc_json',
          timestamp: new Date().toISOString(),
          public_items: extractPublicItemsFromRustdoc(rustdocData),
          modules: extractModulesFromRustdoc(rustdocData),
          feature_flags: [],
          dependencies: []
        };
      }
    }
    
    throw new Error('No rustdoc JSON files found');
  } catch (error) {
    throw new Error(`Failed to parse rustdoc JSON: ${error.message}`);
  }
}

// Extract public items from rustdoc JSON
function extractPublicItemsFromRustdoc(rustdocData) {
  const items = [];
  
  if (rustdocData.index) {
    for (const [id, item] of Object.entries(rustdocData.index)) {
      if (item.visibility === 'public') {
        items.push({
          name: item.name,
          kind: item.kind,
          visibility: 'pub',
          signature: item.signature || generateSignature(item),
          documentation: item.docs
        });
      }
    }
  }
  
  return items;
}

// Extract modules from rustdoc JSON
function extractModulesFromRustdoc(rustdocData) {
  const modules = [];
  
  if (rustdocData.index) {
    for (const [id, item] of Object.entries(rustdocData.index)) {
      if (item.kind === 'module' && item.visibility === 'public') {
        modules.push({
          name: item.name,
          path: item.path,
          documentation: item.docs
        });
      }
    }
  }
  
  return modules;
}

// Parse individual Rust file for public items (basic regex-based parsing)
function parseRustFileForPublicItems(content, filePath) {
  const items = [];
  const lines = content.split('\n');
  
  for (let i = 0; i < lines.length; i++) {
    const line = lines[i].trim();
    
    // Match public functions
    const pubFnMatch = line.match(/^pub\s+fn\s+(\w+)\s*\([^)]*\)(?:\s*->\s*([^{]+))?\s*\{?/);
    if (pubFnMatch) {
      items.push({
        name: pubFnMatch[1],
        kind: 'function',
        visibility: 'pub',
        signature: line,
        location: {
          file: filePath,
          line: i + 1,
          column: 1
        },
        return_type: pubFnMatch[2]?.trim()
      });
    }
    
    // Match public structs
    const pubStructMatch = line.match(/^pub\s+struct\s+(\w+)/);
    if (pubStructMatch) {
      items.push({
        name: pubStructMatch[1],
        kind: 'struct',
        visibility: 'pub',
        signature: line,
        location: {
          file: filePath,
          line: i + 1,
          column: 1
        }
      });
    }
    
    // Match public enums
    const pubEnumMatch = line.match(/^pub\s+enum\s+(\w+)/);
    if (pubEnumMatch) {
      items.push({
        name: pubEnumMatch[1],
        kind: 'enum',
        visibility: 'pub',
        signature: line,
        location: {
          file: filePath,
          line: i + 1,
          column: 1
        }
      });
    }
    
    // Match public traits
    const pubTraitMatch = line.match(/^pub\s+trait\s+(\w+)/);
    if (pubTraitMatch) {
      items.push({
        name: pubTraitMatch[1],
        kind: 'trait',
        visibility: 'pub',
        signature: line,
        location: {
          file: filePath,
          line: i + 1,
          column: 1
        }
      });
    }
    
    // Match public constants
    const pubConstMatch = line.match(/^pub\s+const\s+(\w+)\s*:\s*([^=]+)/);
    if (pubConstMatch) {
      items.push({
        name: pubConstMatch[1],
        kind: 'constant',
        visibility: 'pub',
        signature: line,
        location: {
          file: filePath,
          line: i + 1,
          column: 1
        },
        type: pubConstMatch[2].trim()
      });
    }
    
    // Match public modules
    const pubModMatch = line.match(/^pub\s+mod\s+(\w+)/);
    if (pubModMatch) {
      items.push({
        name: pubModMatch[1],
        kind: 'module',
        visibility: 'pub',
        signature: line,
        location: {
          file: filePath,
          line: i + 1,
          column: 1
        }
      });
    }
  }
  
  return items;
}

// Basic Cargo.toml parser
function parseCargoToml(content) {
  const result = {
    dependencies: [],
    features: []
  };
  
  // Simple regex-based parsing (in production, use a proper TOML parser)
  const dependencySection = content.match(/\[dependencies\]([\s\S]*?)(?:\[|$)/);
  if (dependencySection) {
    const deps = dependencySection[1].match(/^(\w+)\s*=\s*(.+)$/gm);
    if (deps) {
      result.dependencies = deps.map(dep => {
        const [, name, version] = dep.match(/^(\w+)\s*=\s*(.+)$/);
        return {
          name: name.trim(),
          version: version.trim().replace(/['"]/g, '')
        };
      });
    }
  }
  
  const featuresSection = content.match(/\[features\]([\s\S]*?)(?:\[|$)/);
  if (featuresSection) {
    const features = featuresSection[1].match(/^(\w+)\s*=\s*(.+)$/gm);
    if (features) {
      result.features = features.map(feat => {
        const [, name, deps] = feat.match(/^(\w+)\s*=\s*(.+)$/);
        return {
          name: name.trim(),
          dependencies: deps.trim().replace(/[[\]'"]/g, '').split(',').map(s => s.trim())
        };
      });
    }
  }
  
  return result;
}

// Generate basic signature from rustdoc item
function generateSignature(item) {
  switch (item.kind) {
    case 'function':
      return `pub fn ${item.name}()`;
    case 'struct':
      return `pub struct ${item.name}`;
    case 'enum':
      return `pub enum ${item.name}`;
    case 'trait':
      return `pub trait ${item.name}`;
    default:
      return `pub ${item.kind} ${item.name}`;
  }
}

// Strategy 1: Use cargo public-api tool
async function tryCargoPublicApi() {
  try {
    // Check if cargo public-api is installed
    const checkResult = spawn('cargo', ['public-api', '--help'], { 
      stdio: 'pipe',
      timeout: 5000 
    });

    await new Promise((resolve, reject) => {
      checkResult.on('close', (code) => {
        if (code === 0) resolve();
        else reject(new Error('cargo public-api not installed'));
      });
      checkResult.on('error', reject);
    });

    // Run cargo public-api to extract surface
    console.log(chalk.gray('Running cargo public-api --output-format json...'));
    const result = spawn('cargo', ['public-api', '--output-format', 'json'], {
      stdio: 'pipe',
      cwd: process.cwd()
    });

    let output = '';
    let errorOutput = '';

    result.stdout.on('data', (data) => {
      output += data.toString();
    });

    result.stderr.on('data', (data) => {
      errorOutput += data.toString();
    });

    return new Promise((resolve, reject) => {
      result.on('close', (code) => {
        if (code === 0 && output.trim()) {
          try {
            const apiData = JSON.parse(output);
            resolve(transformCargoPublicApiOutput(apiData));
          } catch (parseError) {
            reject(new Error(`Failed to parse cargo public-api output: ${parseError.message}`));
          }
        } else {
          reject(new Error(`cargo public-api failed with code ${code}: ${errorOutput}`));
        }
      });
      result.on('error', reject);
    });
  } catch (error) {
    throw new Error(`cargo public-api strategy failed: ${error.message}`);
  }
}

// Strategy 2: Use rustdoc JSON output
async function tryRustdocJson() {
  try {
    console.log(chalk.gray('Generating rustdoc JSON...'));
    const result = spawn('cargo', ['doc', '--no-deps', '--output-format', 'json'], {
      stdio: 'pipe',
      cwd: process.cwd()
    });

    let output = '';
    let errorOutput = '';

    result.stdout.on('data', (data) => {
      output += data.toString();
    });

    result.stderr.on('data', (data) => {
      errorOutput += data.toString();
    });

    return new Promise((resolve, reject) => {
      result.on('close', (code) => {
        if (code === 0) {
          // Look for generated JSON files in target/doc
          resolve(parseRustdocJson());
        } else {
          reject(new Error(`rustdoc failed with code ${code}: ${errorOutput}`));
        }
      });
      result.on('error', reject);
    });
  } catch (error) {
    throw new Error(`rustdoc JSON strategy failed: ${error.message}`);
  }
}

// Strategy 3: Use syn-based parsing (would require a Rust helper binary)
async function trySynParsing() {
  try {
    // Check if we have a syn-based parser available
    const parserPath = path.join(__dirname, 'tools', 'rust-surface-parser');
    
    try {
      await fs.access(parserPath);
    } catch {
      throw new Error('syn parser not available');
    }

    console.log(chalk.gray('Running syn-based parser...'));
    const result = spawn(parserPath, ['--json'], {
      stdio: 'pipe',
      cwd: process.cwd()
    });

    let output = '';
    let errorOutput = '';

    result.stdout.on('data', (data) => {
      output += data.toString();
    });

    result.stderr.on('data', (data) => {
      errorOutput += data.toString();
    });

    return new Promise((resolve, reject) => {
      result.on('close', (code) => {
        if (code === 0 && output.trim()) {
          try {
            resolve(JSON.parse(output));
          } catch (parseError) {
            reject(new Error(`Failed to parse syn output: ${parseError.message}`));
          }
        } else {
          reject(new Error(`syn parser failed with code ${code}: ${errorOutput}`));
        }
      });
      result.on('error', reject);
    });
  } catch (error) {
    throw new Error(`syn parsing strategy failed: ${error.message}`);
  }
}

// Strategy 4: Basic file scanning fallback
async function basicRustScan() {
  console.log(chalk.yellow('üîç Performing basic Rust file scan...'));
  
  const surface = {
    language: 'rust',
    extraction_method: 'basic_scan',
    timestamp: new Date().toISOString(),
    modules: [],
    public_items: [],
    feature_flags: [],
    dependencies: []
  };

  try {
    // Find Rust source files
    const rustFiles = [];
    const scanDir = async (dir) => {
      try {
        const entries = await fs.readdir(dir, { withFileTypes: true });
        for (const entry of entries) {
          const fullPath = path.join(dir, entry.name);
          if (entry.isDirectory() && entry.name !== 'target') {
            await scanDir(fullPath);
          } else if (entry.isFile() && entry.name.endsWith('.rs')) {
            rustFiles.push(fullPath);
          }
        }
      } catch (error) {
        // Skip inaccessible directories
      }
    };

    // Scan for Rust files
    await scanDir('./src');
    await scanDir('./');

    console.log(chalk.gray(`Found ${rustFiles.length} Rust files`));

    // Parse each file for public items
    for (const file of rustFiles) {
      try {
        const content = await fs.readFile(file, 'utf-8');
        const items = parseRustFileForPublicItems(content, file);
        surface.public_items.push(...items);
      } catch (error) {
        console.log(chalk.yellow(`‚ö†Ô∏è Failed to read ${file}: ${error.message}`));
      }
    }

    // Try to parse Cargo.toml for dependencies and features
    try {
      const cargoContent = await fs.readFile('Cargo.toml', 'utf-8');
      const cargoData = parseCargoToml(cargoContent);
      surface.dependencies = cargoData.dependencies || [];
      surface.feature_flags = cargoData.features || [];
    } catch (error) {
      console.log(chalk.yellow('‚ö†Ô∏è Could not parse Cargo.toml'));
    }

    console.log(chalk.green(`‚úÖ Found ${surface.public_items.length} public items`));
    return surface;

  } catch (error) {
    throw new Error(`Basic Rust scan failed: ${error.message}`);
  }
}

async function extractGoSurface(options) {
  const { extractSurface } = require('./lib/treesitter-surface.cjs');
  return await extractSurface('go', options);
}

async function extractBashSurface(options) {
  const { extractSurface } = require('./lib/treesitter-surface.cjs');
  return await extractSurface('bash', options);
}

/**
 * Tests command - Scaffolding and coverage
 */
async function testsCommand(subcommand, options = {}) {
  console.log(chalk.blue(`üß™ Tests ${subcommand}...`));
  
  switch (subcommand) {
    case 'scaffold':
      return await testsScaffoldCommand(options);
    case 'cover':
      return await testsCoverCommand(options);
    case 'run':
      return await testsRunCommand(options);
    default:
      console.log(chalk.red(`‚ùå Unknown tests subcommand: ${subcommand}`));
      console.log(chalk.gray('Available: scaffold, cover, run'));
      return 1;
  }
}

/**
 * Tests scaffold command - Enhanced CUE contract analysis
 */
async function testsScaffoldCommand(options = {}) {
  const language = options.language || 'typescript';
  const outputDir = options.output || 'tests';
  const force = options.force || false;
  const agentMode = options.agentMode || false;
  
  console.log(chalk.blue(`üìù Generating test skeletons for ${language}...`));
  console.log(chalk.gray(`Output: ${outputDir}`));
  
  if (agentMode) {
    console.log(JSON.stringify({
      phase: 'test_generation_start',
      language,
      outputDir,
      timestamp: new Date().toISOString()
    }));
  }
  
  try {
    // Create output directory
    await fs.mkdir(outputDir, { recursive: true });
    
    // Analyze CUE contracts comprehensively
    const contractAnalysis = await analyzeCueContracts();
    
    console.log(chalk.gray(`Found ${contractAnalysis.schemas.length} schemas`));
    console.log(chalk.gray(`Found ${contractAnalysis.invariants.length} invariants`));
    console.log(chalk.gray(`Found ${contractAnalysis.validationRules.length} validation rules`));
    
    if (agentMode) {
      console.log(JSON.stringify({
        phase: 'contract_analysis_complete',
        schemas: contractAnalysis.schemas.length,
        invariants: contractAnalysis.invariants.length,
        validationRules: contractAnalysis.validationRules.length,
        timestamp: new Date().toISOString()
      }));
    }
    
    // Generate comprehensive test cases
    const testSuites = generateTestSuites(contractAnalysis, language);
    
    let totalTests = 0;
    for (const suite of testSuites) {
      const testFile = path.join(outputDir, suite.fileName);
      
      if (!force && await fileExists(testFile)) {
        console.log(chalk.yellow(`‚ö†Ô∏è  Test file exists: ${testFile}`));
        if (!agentMode) {
          console.log(chalk.gray('Use --force to overwrite'));
        }
        continue;
      }
      
      await fs.writeFile(testFile, suite.content);
      totalTests += suite.testCount;
      
      console.log(chalk.green(`‚úÖ Generated: ${testFile} (${suite.testCount} tests)`));
    }
    
    // Generate test runner configuration
    const runnerConfig = generateTestRunnerConfig(language, testSuites);
    if (runnerConfig) {
      const configFile = path.join(outputDir, runnerConfig.fileName);
      await fs.writeFile(configFile, runnerConfig.content);
      console.log(chalk.green(`‚úÖ Generated: ${configFile}`));
    }
    
    if (agentMode) {
      console.log(JSON.stringify({
        phase: 'test_generation_complete',
        totalTests,
        testSuites: testSuites.length,
        success: true,
        timestamp: new Date().toISOString()
      }));
    } else {
      console.log(chalk.green(`\nüéØ Test generation complete!`));
      console.log(chalk.cyan(`Generated ${totalTests} tests in ${testSuites.length} files`));
      console.log(chalk.blue('\nNext steps:'));
      console.log(chalk.gray('  1. Review generated tests for accuracy'));
      console.log(chalk.gray('  2. Implement mock data generators'));
      console.log(chalk.gray('  3. Run: npm test (or equivalent)'));
      console.log(chalk.gray('  4. Add edge case tests for complex schemas'));
    }
    
    return 0;
  } catch (error) {
    console.error(chalk.red(`‚ùå Test scaffolding failed: ${error.message}`));
    
    if (agentMode) {
      console.log(JSON.stringify({
        phase: 'test_generation_error',
        error: error.message,
        success: false,
        timestamp: new Date().toISOString()
      }));
    }
    
    return 1;
  }
}

/**
 * Analyze CUE contracts comprehensively
 */
async function analyzeCueContracts() {
  const analysis = {
    schemas: [],
    invariants: [],
    validationRules: [],
    profiles: [],
    artifacts: []
  };
  
  try {
    // Read assembly file
    const assemblyFiles = ['arbiter.assembly.cue', 'assembly.cue'];
    let assemblyContent = null;
    let assemblyFile = null;
    
    for (const file of assemblyFiles) {
      try {
        assemblyContent = await fs.readFile(file, 'utf-8');
        assemblyFile = file;
        break;
      } catch (error) {
        // Try next file
      }
    }
    
    if (assemblyContent) {
      // Parse schemas from assembly
      const schemaMatches = assemblyContent.match(/(\w+):\s*{[^}]*}/gs) || [];
      for (const match of schemaMatches) {
        const nameMatch = match.match(/^(\w+):/);
        if (nameMatch) {
          analysis.schemas.push({
            name: nameMatch[1],
            content: match,
            file: assemblyFile,
            type: 'schema'
          });
        }
      }
      
      // Extract validation rules
      const validationMatches = assemblyContent.match(/validation:\s*{[^}]*}/gs) || [];
      for (const match of validationMatches) {
        const rules = match.match(/(\w+):\s*([^,}\n]+)/g) || [];
        for (const rule of rules) {
          analysis.validationRules.push({
            rule: rule.trim(),
            file: assemblyFile,
            type: 'validation'
          });
        }
      }
      
      // Extract profile constraints  
      const profileMatches = assemblyContent.match(/Profile:\s*[^{]*{[^}]*}/gs) || [];
      for (const match of profileMatches) {
        analysis.profiles.push({
          content: match,
          file: assemblyFile,
          type: 'profile'
        });
      }
      
      // Extract artifact definitions
      const artifactMatches = assemblyContent.match(/Artifact:\s*[^{]*{[^}]*}/gs) || [];
      for (const match of artifactMatches) {
        analysis.artifacts.push({
          content: match,
          file: assemblyFile,
          type: 'artifact'
        });
      }
    }
    
    // Find additional CUE files
    const files = await scanProjectFiles('.');
    const cueFiles = files.filter(f => f.type === 'cue' && f.path !== assemblyFile);
    
    for (const file of cueFiles) {
      try {
        const content = await fs.readFile(file.fullPath, 'utf-8');
        
        // Extract constraints and invariants
        const constraints = content.match(/\w+:\s*[><=!~]+[^,\n}]+/g) || [];
        const patterns = content.match(/\w+:\s*=~\s*"[^"]+"/g) || [];
        const ranges = content.match(/\w+:\s*\[[^\]]+\]/g) || [];
        
        analysis.invariants.push(...constraints.map(c => ({
          constraint: c.trim(),
          file: file.path,
          type: 'constraint'
        })));
        
        analysis.invariants.push(...patterns.map(p => ({
          constraint: p.trim(),
          file: file.path,
          type: 'pattern'
        })));
        
        analysis.invariants.push(...ranges.map(r => ({
          constraint: r.trim(),
          file: file.path,
          type: 'range'
        })));
        
      } catch (error) {
        // Skip files we can't read
      }
    }
    
  } catch (error) {
    console.log(chalk.yellow(`‚ö†Ô∏è Contract analysis error: ${error.message}`));
  }
  
  return analysis;
}

/**
 * Generate comprehensive test suites
 */
function generateTestSuites(contractAnalysis, language) {
  const testSuites = [];
  const timestamp = new Date().toISOString();
  
  // Schema validation tests
  if (contractAnalysis.schemas.length > 0) {
    testSuites.push({
      fileName: `schema-validation.${getFileExtension(language)}`,
      testCount: contractAnalysis.schemas.length * 3, // valid, invalid, edge cases
      content: generateSchemaTests(contractAnalysis.schemas, language, timestamp)
    });
  }
  
  // Invariant tests  
  if (contractAnalysis.invariants.length > 0) {
    testSuites.push({
      fileName: `invariant-tests.${getFileExtension(language)}`,
      testCount: contractAnalysis.invariants.length * 2, // positive, negative
      content: generateInvariantTests(contractAnalysis.invariants, language, timestamp)
    });
  }
  
  // Profile compliance tests
  if (contractAnalysis.profiles.length > 0) {
    testSuites.push({
      fileName: `profile-compliance.${getFileExtension(language)}`,
      testCount: contractAnalysis.validationRules.length,
      content: generateProfileTests(contractAnalysis.profiles, contractAnalysis.validationRules, language, timestamp)
    });
  }
  
  // Integration tests
  testSuites.push({
    fileName: `contract-integration.${getFileExtension(language)}`,
    testCount: 5, // End-to-end workflow tests
    content: generateIntegrationTests(contractAnalysis, language, timestamp)
  });
  
  return testSuites;
}

/**
 * Generate schema validation tests
 */
function generateSchemaTests(schemas, language, timestamp) {
  switch (language) {
    case 'typescript':
      return `// Schema Validation Tests - Generated ${timestamp}
// Tests for CUE schema compliance and validation

import { describe, it, expect } from 'vitest';
import { validate } from '../lib/validation'; // Assumes validation library

describe('Schema Validation Tests', () => {
${schemas.map(schema => `
  describe('${schema.name} Schema', () => {
    it('should accept valid ${schema.name} data', () => {
      const validData = generateValid${schema.name}Data();
      const result = validate('${schema.name}', validData);
      expect(result.isValid).toBe(true);
    });
    
    it('should reject invalid ${schema.name} data', () => {
      const invalidData = generateInvalid${schema.name}Data();
      const result = validate('${schema.name}', invalidData);
      expect(result.isValid).toBe(false);
      expect(result.errors).toHaveLength.greaterThan(0);
    });
    
    it('should handle ${schema.name} edge cases', () => {
      const edgeCaseData = generateEdgeCase${schema.name}Data();
      const result = validate('${schema.name}', edgeCaseData);
      // Edge case validation logic here
      expect(result).toBeDefined();
    });
  });
`).join('')}
});

// Helper functions for test data generation
${schemas.map(schema => `
function generateValid${schema.name}Data() {
  // TODO: Generate valid test data for ${schema.name}
  // Based on schema: ${schema.content.substring(0, 100)}...
  return {};
}

function generateInvalid${schema.name}Data() {
  // TODO: Generate invalid test data for ${schema.name}
  return {};
}

function generateEdgeCase${schema.name}Data() {
  // TODO: Generate edge case test data for ${schema.name}
  return {};
}
`).join('')}
`;

    case 'python':
      return `"""Schema Validation Tests - Generated ${timestamp}
Tests for CUE schema compliance and validation
"""

import pytest
from lib.validation import validate  # Assumes validation library

class TestSchemaValidation:
${schemas.map(schema => {
  const lowerName = schema.name.toLowerCase();
  return `
    def test_valid_${lowerName}_data(self):
        """Test ${schema.name} schema with valid data"""
        valid_data = self.generate_valid_${lowerName}_data()
        result = validate('${schema.name}', valid_data)
        assert result['is_valid'] is True
    
    def test_invalid_${lowerName}_data(self):
        """Test ${schema.name} schema with invalid data"""
        invalid_data = self.generate_invalid_${lowerName}_data()
        result = validate('${schema.name}', invalid_data)
        assert result['is_valid'] is False
        assert len(result['errors']) > 0
    
    def test_${lowerName}_edge_cases(self):
        """Test ${schema.name} schema with edge cases"""
        edge_data = self.generate_edge_case_${lowerName}_data()
        result = validate('${schema.name}', edge_data)
        assert result is not None
    
    def generate_valid_${lowerName}_data(self):
        """Generate valid test data for ${schema.name}"""
        # TODO: Implement based on schema
        return {}
    
    def generate_invalid_${lowerName}_data(self):
        """Generate invalid test data for ${schema.name}"""
        # TODO: Implement based on schema
        return {}
    
    def generate_edge_case_${lowerName}_data(self):
        """Generate edge case test data for ${schema.name}"""
        # TODO: Implement based on schema
        return {}
`;
}).join('')}
`;

    default:
      return `// Schema tests for ${language} - ${timestamp}\n// TODO: Implement schema tests`;
  }
}

/**
 * Generate invariant tests
 */
function generateInvariantTests(invariants, language, timestamp) {
  switch (language) {
    case 'typescript':
      return `// Invariant Tests - Generated ${timestamp}
// Tests for CUE constraints and business rules

import { describe, it, expect } from 'vitest';

describe('Invariant Tests', () => {
${invariants.map((inv, idx) => `
  it('should enforce invariant: ${inv.constraint}', () => {
    // From file: ${inv.file}
    // Type: ${inv.type}
    
    // TODO: Implement positive test case
    expect(true).toBe(true);
  });
  
  it('should reject violation of: ${inv.constraint}', () => {
    // TODO: Implement negative test case
    expect(true).toBe(true);
  });
`).join('')}
});
`;

    case 'python':
      return `"""Invariant Tests - Generated ${timestamp}
Tests for CUE constraints and business rules
"""

import pytest

class TestInvariants:
${invariants.map((inv, idx) => `
    def test_enforce_invariant_${idx + 1}(self):
        """Test invariant: ${inv.constraint}"""
        # From file: ${inv.file}
        # Type: ${inv.type}
        
        # TODO: Implement positive test case
        assert True
    
    def test_reject_violation_${idx + 1}(self):
        """Test violation of: ${inv.constraint}"""
        # TODO: Implement negative test case
        assert True
`).join('')}
`;

    default:
      return `// Invariant tests for ${language} - ${timestamp}\n// TODO: Implement invariant tests`;
  }
}

/**
 * Generate profile compliance tests
 */
function generateProfileTests(profiles, validationRules, language, timestamp) {
  switch (language) {
    case 'typescript':
      return `// Profile Compliance Tests - Generated ${timestamp}
// Tests for profile requirements and validation rules

import { describe, it, expect } from 'vitest';

describe('Profile Compliance Tests', () => {
${validationRules.map(rule => `
  it('should pass validation rule: ${rule.rule}', () => {
    // From file: ${rule.file}
    
    // TODO: Implement validation test
    expect(true).toBe(true);
  });
`).join('')}

  it('should meet all profile requirements', () => {
    // Comprehensive profile compliance test
    // TODO: Implement end-to-end profile validation
    expect(true).toBe(true);
  });
});
`;

    default:
      return `// Profile tests for ${language} - ${timestamp}\n// TODO: Implement profile tests`;
  }
}

/**
 * Generate integration tests
 */
function generateIntegrationTests(contractAnalysis, language, timestamp) {
  switch (language) {
    case 'typescript':
      return `// Contract Integration Tests - Generated ${timestamp}
// End-to-end tests for contract interactions

import { describe, it, expect } from 'vitest';

describe('Contract Integration Tests', () => {
  it('should validate complete workflow', () => {
    // Test full contract validation pipeline
    // TODO: Implement workflow test
    expect(true).toBe(true);
  });
  
  it('should handle contract composition', () => {
    // Test multiple contracts working together
    // TODO: Implement composition test  
    expect(true).toBe(true);
  });
  
  it('should enforce cross-contract invariants', () => {
    // Test invariants across multiple schemas
    // TODO: Implement cross-contract test
    expect(true).toBe(true);
  });
  
  it('should validate performance constraints', () => {
    // Test performance requirements from profiles
    // TODO: Implement performance test
    expect(true).toBe(true);
  });
  
  it('should handle error scenarios gracefully', () => {
    // Test error handling and recovery
    // TODO: Implement error scenario test
    expect(true).toBe(true);
  });
});
`;

    default:
      return `// Integration tests for ${language} - ${timestamp}\n// TODO: Implement integration tests`;
  }
}

/**
 * Generate test runner configuration
 */
function generateTestRunnerConfig(language, testSuites) {
  switch (language) {
    case 'typescript':
      return {
        fileName: 'vitest.config.ts',
        content: `// Test Configuration - Generated ${new Date().toISOString()}
import { defineConfig } from 'vitest/config';

export default defineConfig({
  test: {
    globals: true,
    environment: 'node',
    include: ['**/*.test.ts'],
    coverage: {
      reporter: ['text', 'json', 'html'],
      threshold: {
        global: {
          branches: 80,
          functions: 80,
          lines: 80,
          statements: 80,
        },
      },
    },
  },
});
`
      };
      
    case 'python':
      return {
        fileName: 'pytest.ini',
        content: `# Test Configuration - Generated ${new Date().toISOString()}
[tool:pytest]
testpaths = tests
python_files = *.test.py
python_classes = Test*
python_functions = test_*
addopts = 
    --verbose
    --cov=lib
    --cov-report=html
    --cov-report=term
    --cov-fail-under=80
`
      };
      
    default:
      return null;
  }
}

/**
 * Get file extension for language
 */
function getFileExtension(language) {
  const extensions = {
    typescript: 'test.ts',
    python: 'test.py',
    rust: 'rs',
    go: 'go',
    bash: 'sh'
  };
  return extensions[language] || 'txt';
}

/**
 * Check if file exists
 */
async function fileExists(filePath) {
  try {
    await fs.access(filePath);
    return true;
  } catch {
    return false;
  }
}

/**
 * Version command - Semver-aware version management
 */
async function versionCommand(subcommand, options = {}) {
  console.log(chalk.blue(`üì¶ Version ${subcommand}...`));
  
  switch (subcommand) {
    case 'plan':
      return await versionPlanCommand(options);
    case 'release':
      return await versionReleaseCommand(options);
    default:
      console.log(chalk.red(`‚ùå Unknown version subcommand: ${subcommand}`));
      console.log(chalk.gray('Available: plan, release'));
      return 1;
  }
}

/**
 * Version plan command
 */
async function versionPlanCommand(options = {}) {
  console.log(chalk.blue('üìã Analyzing API changes for semver recommendation...'));
  
  const currentFile = options.current || 'surface.json';
  const previousFile = options.previous;
  const outputFile = options.output || 'version_plan.json';
  const strict = options.strict || false;
  
  try {
    let currentSurface = null;
    let previousSurface = null;
    
    // Read current surface
    if (await fileExists(currentFile)) {
      const content = await fs.readFile(currentFile, 'utf8');
      currentSurface = JSON.parse(content);
    } else {
      console.log(chalk.yellow(`‚ö†Ô∏è  Current surface file not found: ${currentFile}`));
      console.log(chalk.gray('Run: arbiter surface <language> to generate'));
      return 1;
    }
    
    // Read previous surface if provided
    if (previousFile && await fileExists(previousFile)) {
      const content = await fs.readFile(previousFile, 'utf8');
      previousSurface = JSON.parse(content);
    }
    
    // Analyze changes using Tree-sitter delta computation
    const analysis = await analyzeApiChanges(currentSurface, previousSurface);
    
    // Create version plan
    const versionPlan = {
      metadata: {
        generatedAt: new Date().toISOString(),
        currentSurface: currentFile,
        previousSurface: previousFile,
        strict
      },
      recommendation: analysis.recommendation,
      changes: analysis.changes,
      reasoning: analysis.reasoning
    };
    
    // Write plan
    await fs.writeFile(outputFile, JSON.stringify(versionPlan, null, 2));
    
    // Display results
    console.log(chalk.green(`‚úÖ Version analysis complete`));
    console.log(chalk.bold(`Recommended version bump: ${analysis.recommendation.type}`));
    
    if (analysis.changes.breaking.length > 0) {
      console.log(chalk.red('\nüí• Breaking changes detected:'));
      analysis.changes.breaking.forEach(change => {
        console.log(chalk.red(`  - ${change}`));
      });
      
      if (strict) {
        console.log(chalk.red('‚ùå Strict mode: Breaking changes not allowed'));
        return 1;
      }
    }
    
    if (analysis.changes.features.length > 0) {
      console.log(chalk.blue('\nüÜï New features:'));
      analysis.changes.features.forEach(change => {
        console.log(chalk.blue(`  - ${change}`));
      });
    }
    
    if (analysis.changes.fixes.length > 0) {
      console.log(chalk.green('\nüêõ Fixes:'));
      analysis.changes.fixes.forEach(change => {
        console.log(chalk.green(`  - ${change}`));
      });
    }
    
    console.log(chalk.gray(`\nüìÑ Full analysis saved to: ${outputFile}`));
    
    return 0;
  } catch (error) {
    console.error(chalk.red(`‚ùå Version planning failed: ${error.message}`));
    return 1;
  }
}

/**
 * Analyze semver changes between surfaces
 */
async function analyzeApiChanges(current, previous) {
  const changes = {
    breaking: [],
    features: [],
    fixes: []
  };
  
  if (!previous) {
    return {
      recommendation: { type: 'minor', version: '0.1.0' },
      changes,
      reasoning: 'Initial version - no previous surface for comparison'
    };
  }
  
  // Handle multi-language surfaces (new format) vs single language (legacy)
  let allDeltas = [];
  let overallBump = 'NONE';
  
  if (current.languages && previous.languages) {
    // Multi-language comparison using Tree-sitter delta computation
    const { computeSurfaceDelta } = require('./lib/treesitter-surface.cjs');
    
    const allLanguages = new Set([...Object.keys(current.languages), ...Object.keys(previous.languages)]);
    
    for (const language of allLanguages) {
      const currentLangSurface = current.languages[language];
      const previousLangSurface = previous.languages[language];
      
      if (currentLangSurface && previousLangSurface) {
        // Compare existing language surfaces
        const delta = computeSurfaceDelta(previousLangSurface, currentLangSurface);
        allDeltas.push({ language, ...delta });
        
        // Update overall bump requirement
        if (delta.required_bump === 'MAJOR' || overallBump === 'NONE') {
          overallBump = delta.required_bump;
        } else if (delta.required_bump === 'MINOR' && overallBump !== 'MAJOR') {
          overallBump = delta.required_bump;
        } else if (delta.required_bump === 'PATCH' && overallBump === 'NONE') {
          overallBump = delta.required_bump;
        }
      } else if (currentLangSurface && !previousLangSurface) {
        // New language added - minor version bump
        changes.features.push(`Added ${language} language support`);
        if (overallBump === 'NONE') overallBump = 'MINOR';
      } else if (!currentLangSurface && previousLangSurface) {
        // Language removed - breaking change
        changes.breaking.push(`Removed ${language} language support`);
        overallBump = 'MAJOR';
      }
    }
    
    // Aggregate changes from all deltas
    for (const delta of allDeltas) {
      delta.breaking_changes.forEach(change => {
        if (change.kind === 'removed') {
          changes.breaking.push(`${delta.language}: Removed ${change.kind} '${change.name}'`);
        } else {
          changes.breaking.push(`${delta.language}: Modified ${change.kind} '${change.name}' (${change.change_type})`);
        }
      });
      
      delta.added.forEach(item => {
        changes.features.push(`${delta.language}: Added ${item.kind} '${item.name}'`);
      });
      
      delta.modified.filter(m => m.change_type === 'non-breaking').forEach(item => {
        changes.fixes.push(`${delta.language}: Updated ${item.kind} '${item.name}'`);
      });
    }
    
  } else {
    // Legacy single-language format - fallback to simple comparison
    const currentExports = current.exports || current.public_items || [];
    const previousExports = previous.exports || previous.public_items || [];
    
    const currentNames = new Set(currentExports.map(e => e.name));
    const previousNames = new Set(previousExports.map(e => e.name));
    
    // Check for removed exports (breaking)
    previousNames.forEach(name => {
      if (!currentNames.has(name)) {
        changes.breaking.push(`Removed export: ${name}`);
      }
    });
    
    // Check for new exports (features)  
    currentNames.forEach(name => {
      if (!previousNames.has(name)) {
        changes.features.push(`Added export: ${name}`);
      }
    });
    
    // Determine bump type
    if (changes.breaking.length > 0) {
      overallBump = 'MAJOR';
    } else if (changes.features.length > 0) {
      overallBump = 'MINOR';
    } else if (changes.fixes.length > 0) {
      overallBump = 'PATCH';
    }
  }
  
  // Convert bump to recommendation format
  let recommendationType = 'patch';
  if (overallBump === 'MAJOR') recommendationType = 'major';
  else if (overallBump === 'MINOR') recommendationType = 'minor';
  else if (overallBump === 'PATCH') recommendationType = 'patch';
  
  return {
    recommendation: { type: recommendationType, version: 'TBD' },
    changes,
    deltas: allDeltas,
    reasoning: `${changes.breaking.length} breaking, ${changes.features.length} features, ${changes.fixes.length} fixes`
  };
}

/**
 * Trace command - Build traceability graph and generate reports
 */
async function traceCommand(subcommand, options = {}) {
  console.log(chalk.blue(`üîó Traceability ${subcommand}...`));
  
  switch (subcommand) {
    case 'link':
      return await traceLinkCommand(options);
    case 'report':
      return await traceReportCommand(options);
    default:
      console.log(chalk.red(`‚ùå Unknown trace subcommand: ${subcommand}`));
      console.log(chalk.gray('Available: link, report'));
      console.log(chalk.gray(''));
      console.log(chalk.gray('Examples:'));
      console.log(chalk.gray('  arbiter trace link'));
      console.log(chalk.gray('  arbiter trace report --out TRACE.json'));
      return 1;
  }
}

/**
 * Trace link command - Build traceability graph
 */
async function traceLinkCommand(options = {}) {
  console.log(chalk.blue('üîó Building traceability links...'));
  
  try {
    const { generateTraceReport } = require('./lib/traceability.cjs');
    
    // Generate traceability graph (this builds the links internally)
    const report = await generateTraceReport('trace_links.json');
    
    // Display summary
    console.log(chalk.green('‚úÖ Traceability graph built successfully'));
    console.log(chalk.gray(`Found ${report.summary.artifacts.total} artifacts:`));
    console.log(chalk.gray(`  - ${report.summary.artifacts.requirements} requirements`));
    console.log(chalk.gray(`  - ${report.summary.artifacts.specifications} specifications`));  
    console.log(chalk.gray(`  - ${report.summary.artifacts.tests} tests`));
    console.log(chalk.gray(`  - ${report.summary.artifacts.code} code artifacts`));
    console.log(chalk.gray(`Created ${report.summary.links.total} traceability links`));
    
    // Display coverage
    console.log(chalk.blue('\nüìä Coverage Summary:'));
    Object.entries(report.summary.coverage).forEach(([type, stats]) => {
      const percent = stats.total > 0 ? ((stats.linked / stats.total) * 100).toFixed(1) : '100.0';
      const color = percent >= 80 ? chalk.green : percent >= 60 ? chalk.yellow : chalk.red;
      console.log(color(`  ${type}: ${stats.linked}/${stats.total} (${percent}%)`));
    });
    
    // Display gaps
    if (report.gaps.length > 0) {
      console.log(chalk.yellow(`\n‚ö†Ô∏è  Found ${report.gaps.length} traceability gaps:`));
      report.gaps.slice(0, 5).forEach(gap => {
        console.log(chalk.yellow(`  - ${gap.description}`));
      });
      if (report.gaps.length > 5) {
        console.log(chalk.gray(`  ... and ${report.gaps.length - 5} more (see TRACE.json)`));
      }
    }
    
    console.log(chalk.green(`\n‚úÖ Traceability links saved to: trace_links.json`));
    return 0;
    
  } catch (error) {
    console.error(chalk.red('‚ùå Traceability linking failed:'), error.message);
    return 1;
  }
}

/**
 * Trace report command - Generate TRACE.json report
 */
async function traceReportCommand(options = {}) {
  const outputFile = options.out || options.output || 'TRACE.json';
  
  console.log(chalk.blue('üìã Generating traceability report...'));
  
  try {
    const { generateTraceReport } = require('./lib/traceability.cjs');
    
    const report = await generateTraceReport(outputFile);
    
    // Display detailed summary
    console.log(chalk.green('‚úÖ Traceability report generated successfully'));
    console.log(chalk.bold('\nüìä Artifact Summary:'));
    console.log(chalk.gray(`  Requirements:    ${report.summary.artifacts.requirements}`));
    console.log(chalk.gray(`  Specifications:  ${report.summary.artifacts.specifications}`));
    console.log(chalk.gray(`  Tests:          ${report.summary.artifacts.tests}`));
    console.log(chalk.gray(`  Code Artifacts: ${report.summary.artifacts.code}`));
    console.log(chalk.gray(`  Total:          ${report.summary.artifacts.total}`));
    
    console.log(chalk.bold('\nüîó Link Summary:'));
    console.log(chalk.gray(`  Strong Links:   ${report.summary.links.strong} (>70% confidence)`));
    console.log(chalk.gray(`  Medium Links:   ${report.summary.links.medium} (40-70% confidence)`));
    console.log(chalk.gray(`  Weak Links:     ${report.summary.links.weak} (<40% confidence)`));
    console.log(chalk.gray(`  Total Links:    ${report.summary.links.total}`));
    
    console.log(chalk.bold('\nüìà Coverage Analysis:'));
    Object.entries(report.summary.coverage).forEach(([type, stats]) => {
      const percent = stats.total > 0 ? ((stats.linked / stats.total) * 100).toFixed(1) : '100.0';
      const color = percent >= 80 ? chalk.green : percent >= 60 ? chalk.yellow : chalk.red;
      console.log(color(`  ${type.padEnd(14)}: ${stats.linked.toString().padStart(3)}/${stats.total.toString().padStart(3)} (${percent.padStart(5)}%)`));
    });
    
    // Display recommendations
    if (report.recommendations.length > 0) {
      console.log(chalk.bold('\nüí° Recommendations:'));
      report.recommendations.forEach(rec => {
        const priority = rec.priority === 'high' ? chalk.red('[HIGH]') : 
                        rec.priority === 'medium' ? chalk.yellow('[MED]') : chalk.gray('[LOW]');
        console.log(`  ${priority} ${rec.description}`);
      });
    }
    
    // Display significant gaps
    const criticalGaps = report.gaps.filter(g => g.type === 'missing_specification' || g.type === 'missing_tests');
    if (criticalGaps.length > 0) {
      console.log(chalk.bold('\n‚ö†Ô∏è  Critical Gaps:'));
      criticalGaps.slice(0, 3).forEach(gap => {
        console.log(chalk.red(`  - ${gap.description}`));
      });
      if (criticalGaps.length > 3) {
        console.log(chalk.gray(`  ... and ${criticalGaps.length - 3} more critical gaps`));
      }
    }
    
    console.log(chalk.green(`\nüìÑ Full report saved to: ${outputFile}`));
    console.log(chalk.gray('Use this file for CI integration and compliance tracking.'));
    
    return 0;
    
  } catch (error) {
    console.error(chalk.red('‚ùå Traceability report failed:'), error.message);
    return 1;
  }
}

/**
 * Show comprehensive help
 */
function showHelp() {
  console.log(`
${chalk.bold('Arbiter CLI')} - Comprehensive CUE validation and management

${chalk.bold('USAGE:')}
  arbiter <command> [options]

${chalk.bold('CORE COMMANDS (Phase 1):')}
  import [path]              Import project into Arbiter
  generate [--template]      Generate baseline CUE files  
  check [patterns...]        Validate CUE files
  health                     Check API server health

${chalk.bold('ADVANCED COMMANDS (Phase 2):')}
  watch [path]               File watcher with live validation
  surface <language>         Extract API surface from code
  trace <link|report>        Build traceability graph and generate reports
  validate <files...>        Explicit validation with schema
  export <files...>          Export to various formats

${chalk.bold('DEVELOPMENT COMMANDS (Phase 3):')}
  init [project]             Initialize new CUE project
  create <type>              Interactive schema creation
  template <action>          Manage CUE templates
  diff <old> <new>           Compare schema versions
  migrate [patterns...]      Apply schema evolution

${chalk.bold('TESTING & QUALITY (Phase 4):')}
  execute <epic>             Execute Epic v2 code generation
  tests <action>             Test scaffolding and coverage
    scaffold                   Generate test skeletons from invariants
    cover                      Analyze contract coverage
    run                        Run unified test harness

${chalk.bold('INTEGRATION & DOCS (Phase 5):')}
  version <action>           Semver-aware version management
    plan                       Analyze API changes and recommend bump
    release                    Update manifests and generate changelog
  ide recommend              Generate IDE configuration
  sync                       Synchronize project manifests
  integrate                  Generate CI/CD workflows
  docs <type>                Generate documentation
  examples <type>            Generate example projects
  explain                    Plain-English assembly explanation
  preview                    Show generation preview

${chalk.bold('OPTIONS:')}
  --template <type>          Template type: library, cli, service, job
  --api-url <url>            API server URL (default: http://localhost:4001)
  --agent-mode               Output NDJSON for agent consumption
  --format <type>            Output format: table, json, yaml
  --verbose, -v              Verbose output
  --dry-run                  Show what would be done without doing it
  --force                    Force overwrite existing files

${chalk.bold('EXAMPLES:')}
  # Core workflow
  arbiter import .                          # Import current directory
  arbiter generate --template library       # Generate library profile
  arbiter check                             # Validate CUE files
  
  # Advanced features
  arbiter watch --agent-mode                # Start file watcher for agents
  arbiter surface typescript --output api.json  # Extract TypeScript API
  arbiter version plan --strict             # Analyze semver changes
  
  # Test generation (revolutionary)
  arbiter tests scaffold --language typescript  # Generate tests from CUE
  arbiter tests cover --threshold 0.9       # Analyze contract coverage
  
  # Integration
  arbiter sync --language all --dry-run     # Preview manifest sync
  arbiter integrate --provider github       # Generate CI/CD workflows
  arbiter docs schema --format html         # Generate schema documentation

${chalk.bold('AGENT MODE:')}
  Use --agent-mode for NDJSON output suitable for AI agent consumption.
  Many commands support this mode for programmatic integration.
`);
}

// Main CLI logic with comprehensive command routing
async function main() {
  const args = process.argv.slice(2);
  const command = args[0];
  const subcommand = args[1];
  
  // Parse global options
  const options = parseOptions(args);
  
  try {
    switch (command) {
      // Phase 1: Core Commands
      case 'import':
        return await importCommand(args[1] || '.');
      
      case 'generate':
        const templateIndex = args.indexOf('--template');
        const template = templateIndex !== -1 ? args[templateIndex + 1] : 'library';
        return await generateCommand(template);
      
      case 'check':
        return await checkCommand();
      
      case 'health':
        return await healthCommand();

      // Requirements pipeline commands
      case 'requirements':
        return await requirementsCommand(subcommand, args[2], options);
      
      case 'spec':
        return await specCommand(subcommand, options);
      
      // Phase 2: Advanced Commands
      case 'watch':
        // Find the path argument (first non-option argument after 'watch')
        let watchPath = '.';
        for (let i = 1; i < args.length; i++) {
          if (!args[i].startsWith('--')) {
            watchPath = args[i];
            break;
          }
        }
        return await watchCommand(watchPath, {
          agentMode: options.agentMode,
          debounce: options.debounce,
          noValidate: options.noValidate
        });
      
      case 'surface':
        if (!subcommand) {
          console.error(chalk.red('‚ùå Language required'));
          console.log(chalk.gray('Usage: arbiter surface <language>'));
          console.log(chalk.gray('Languages: typescript, python, rust, go, bash'));
          return 1;
        }
        return await surfaceCommand(subcommand, {
          output: options.output,
          diff: options.diff,
          includePrivate: options.includePrivate,
          verbose: options.verbose
        });
      
      case 'trace':
        return await traceCommand(subcommand, options);
      
      case 'validate':
        return await validateCommand(args.slice(1), options);
      
      case 'export':
        return await exportCommand(args.slice(1), options);
      
      // Phase 3: Development Commands
      case 'init':
        return await initCommand(subcommand, options);
      
      case 'create':
        return await createCommand(subcommand, options);
      
      case 'template':
        return await templateCommand(subcommand, args[2], options);
      
      case 'diff':
        return await diffCommand(args[1], args[2], options);
      
      case 'migrate':
        return await migrateCommand(args.slice(1), options);
      
      // Phase 4: Testing & Quality
      case 'execute':
        return await executeCommand(subcommand, options);
      
      case 'tests':
        return await testsCommand(subcommand, options);
      
      // Phase 5: Integration & Documentation
      case 'version':
        return await versionCommand(subcommand, options);
      
      case 'ide':
        return await ideCommand(options);
      
      case 'sync':
        return await syncCommand(options);
      
      case 'integrate':
        return await integrateCommand(options);
      
      case 'docs':
        return await docsCommand(subcommand, options);
      
      case 'examples':
        return await examplesCommand(subcommand, options);
      
      case 'explain':
        return await explainCommand(options);
      
      case 'preview':
        return await previewCommand(options);
      
      // Help and meta commands
      case 'help':
      case '--help':
      case '-h':
        showHelp();
        return 0;
      
      case 'version':
      case '--version':
      case '-v':
        if (subcommand && !['plan', 'release'].includes(subcommand)) {
          console.log('Arbiter CLI v0.1.0');
          return 0;
        }
        return await versionCommand(subcommand, options);
      
      default:
        if (!command) {
          showHelp();
          return 0;
        }
        console.error(chalk.red(`Unknown command: ${command}`));
        console.log('Run "arbiter help" for usage information');
        console.log(chalk.gray('\nAvailable commands:'));
        Object.entries(COMMANDS).forEach(([cmd, desc]) => {
          console.log(chalk.gray(`  ${cmd.padEnd(12)} ${desc}`));
        });
        return 1;
    }
  } catch (error) {
    console.error(chalk.red('‚ùå Command failed:'), error.message);
    if (options.verbose) {
      console.error(error.stack);
    }
    return 1;
  }
}

/**
 * Parse command line options
 */
function parseOptions(args) {
  const options = {
    verbose: false,
    dryRun: false,
    force: false,
    agentMode: false,
    format: 'table',
    output: null,
    out: null, // for --out parameter
    fromRequirements: null, // for --from-requirements
    template: null, // for --template
    debounce: DEFAULT_CONFIG.watchDebounce,
    noValidate: false,
    diff: false,
    includePrivate: false
  };
  
  for (let i = 0; i < args.length; i++) {
    const arg = args[i];
    
    switch (arg) {
      case '--verbose':
      case '-v':
        options.verbose = true;
        break;
      case '--dry-run':
        options.dryRun = true;
        break;
      case '--force':
      case '-f':
        options.force = true;
        break;
      case '--agent-mode':
        options.agentMode = true;
        break;
      case '--format':
        if (i + 1 < args.length) options.format = args[++i];
        break;
      case '--output':
      case '-o':
        if (i + 1 < args.length) options.output = args[++i];
        break;
      case '--out':
        if (i + 1 < args.length) options.out = args[++i];
        break;
      case '--from-requirements':
        if (i + 1 < args.length) options.fromRequirements = args[++i];
        break;
      case '--template':
        if (i + 1 < args.length) options.template = args[++i];
        break;
      case '--debounce':
        if (i + 1 < args.length) {
          const debounceValue = parseInt(args[++i], 10);
          if (!isNaN(debounceValue)) options.debounce = debounceValue;
        }
        break;
      case '--no-validate':
        options.noValidate = true;
        break;
      case '--diff':
        options.diff = true;
        break;
      case '--include-private':
        options.includePrivate = true;
        break;
    }
  }
  
  return options;
}

/**
 * Stub implementations for remaining commands
 * These provide basic structure and helpful messages
 */

async function validateCommand(files, options) {
  console.log(chalk.blue('üîç Validate command'));
  console.log(chalk.yellow('üìã Advanced validation not yet implemented'));
  console.log(chalk.gray('This will provide explicit schema validation'));
  return 0;
}

async function exportCommand(files, options) {
  console.log(chalk.blue('üì§ Export command'));
  console.log(chalk.yellow('üìã Export functionality not yet implemented'));
  console.log(chalk.gray('This will export CUE to various formats'));
  return 0;
}

async function initCommand(projectName, options) {
  console.log(chalk.blue('üöÄ Init command'));
  console.log(chalk.yellow('üìã Project initialization not yet implemented'));
  console.log(chalk.gray('This will initialize new CUE projects with templates'));
  return 0;
}

async function createCommand(type, options) {
  console.log(chalk.blue('‚ú® Create command'));
  console.log(chalk.yellow('üìã Interactive creation not yet implemented'));
  console.log(chalk.gray('This will provide interactive schema creation'));
  return 0;
}

async function templateCommand(action, template, options) {
  console.log(chalk.blue('üìã Template command'));
  console.log(chalk.yellow('üìã Template management not yet implemented'));
  console.log(chalk.gray('This will manage CUE schema templates'));
  return 0;
}

async function diffCommand(oldFile, newFile, options) {
  console.log(chalk.blue('üîç Diff command'));
  console.log(chalk.yellow('üìã Schema comparison not yet implemented'));
  console.log(chalk.gray('This will compare schema versions'));
  return 0;
}

async function migrateCommand(patterns, options) {
  console.log(chalk.blue('üîÑ Migrate command'));
  console.log(chalk.yellow('üìã Schema migration not yet implemented'));
  console.log(chalk.gray('This will apply schema evolution changes'));
  return 0;
}

async function executeCommand(epic, options) {
  console.log(chalk.blue('‚ö° Execute command'));
  console.log(chalk.yellow('üìã Epic v2 execution not yet implemented'));
  console.log(chalk.gray('This will execute Epic v2 for code generation'));
  return 0;
}

async function testsCoverCommand(options) {
  console.log(chalk.blue('üìä Computing contract coverage...'));
  console.log(chalk.yellow('üìã Coverage analysis not yet implemented'));
  console.log(chalk.gray('This will analyze contract coverage metrics'));
  return 0;
}

async function testsRunCommand(options) {
  console.log(chalk.blue('üèÉ Running unified test harness...'));
  console.log(chalk.yellow('üìã Unified test harness not yet implemented'));
  console.log(chalk.gray('This will run comprehensive test suite'));
  return 0;
}

async function versionReleaseCommand(options) {
  console.log(chalk.blue('üöÄ Version release command'));
  console.log(chalk.yellow('üìã Release management not yet implemented'));
  console.log(chalk.gray('This will update manifests and generate changelog'));
  return 0;
}

async function ideCommand(options) {
  console.log(chalk.blue('üí° IDE command'));
  console.log(chalk.yellow('üìã IDE configuration not yet implemented'));
  console.log(chalk.gray('This will generate IDE configuration'));
  return 0;
}

async function syncCommand(options) {
  console.log(chalk.blue('üîÑ Sync command'));
  console.log(chalk.yellow('üìã Manifest synchronization not yet implemented'));
  console.log(chalk.gray('This will synchronize project manifests'));
  return 0;
}

async function integrateCommand(options) {
  console.log(chalk.blue('üîó Integrate command'));
  console.log(chalk.yellow('üìã CI/CD integration not yet implemented'));
  console.log(chalk.gray('This will generate CI/CD workflows'));
  return 0;
}

async function docsCommand(type, options) {
  console.log(chalk.blue('üìö Generating documentation...'));
  
  if (!type) {
    console.error(chalk.red('‚ùå Documentation type required'));
    console.log(chalk.gray('Usage: arbiter docs <type> [options]'));
    console.log(chalk.gray('Types: schema, assembly'));
    return 1;
  }

  try {
    let outputFile = options.out;
    let content = '';

    switch (type) {
      case 'schema':
        content = await generateSchemaDocumentation();
        outputFile = outputFile || 'SCHEMA_DOCUMENTATION.md';
        break;
      
      case 'assembly':
        content = await generateAssemblyDocumentation();
        outputFile = outputFile || 'ASSEMBLY_DOCUMENTATION.md';
        break;
      
      default:
        console.error(chalk.red(`‚ùå Unknown documentation type: ${type}`));
        console.log(chalk.gray('Available types: schema, assembly'));
        return 1;
    }

    // Write documentation file
    await fs.writeFile(outputFile, content);
    console.log(chalk.green(`‚úÖ Generated ${outputFile}`));

    // Agent mode output
    if (options.agentMode) {
      console.log(JSON.stringify({
        phase: 'docs_generation',
        type,
        output: outputFile,
        success: true
      }));
    }

    return 0;
  } catch (error) {
    console.error(chalk.red('‚ùå Documentation generation failed:'), error.message);
    
    if (options.agentMode) {
      console.log(JSON.stringify({
        phase: 'docs_generation',
        type,
        error: error.message,
        success: false
      }));
    }
    
    return 1;
  }
}

// Generate schema documentation from CUE files
async function generateSchemaDocumentation() {
  const timestamp = new Date().toISOString();
  
  return `# Arbiter Schema Documentation

**Generated:** ${timestamp}  
**API Version:** arbiter.dev/v2

## Overview

This documentation describes the CUE schemas and data structures used by the Arbiter framework.

## Core Schemas

### Artifact Schema

The Artifact schema defines the structure of buildable and deployable artifacts.

\`\`\`cue
Artifact: {
    kind: string        // artifact type: "library" | "service" | "cli" | "policy_bundle"
    name?: string       // optional artifact name
    language: string    // primary language: "typescript" | "go" | "rust" | "python" | "cue"
    
    build: {
        tool: string           // build tool: "bun" | "go" | "cargo" | "cue"
        targets: [...string]   // build targets/patterns
        outputs?: [...string]  // optional output specifications
    }
    
    packaging?: {
        publish: bool
        registry: string
        artifact: string
    }
}
\`\`\`

### Profile Schema

Profiles define validation rules, quality gates, and operational characteristics.

\`\`\`cue
Profile: {
    semver?: string              // version strategy: "strict" | "loose"
    determinism?: bool           // require deterministic outputs
    
    apiSurface?: {
        source: string          // "generated" | "manual"
        file: string           // path to surface definition
    }
    
    contracts?: {
        forbidBreaking: bool
        invariants: [...{
            name: string
            description: string
            rule: string
        }]
    }
    
    gates?: {
        quality?: {
            testCoverage?: number
            lintPassing?: bool
            typeCheck?: bool
        }
        performance?: {
            responseTime?: string
            payloadSize?: string
        }
    }
}
\`\`\`

## Quality Gates

Quality gates are automated checks that must pass for validation to succeed.

| Gate Type | Description | Example Rule |
|-----------|-------------|--------------|
| Quality | Code quality metrics | Test coverage > 90% |
| Performance | Runtime performance | Response time < 750ms |
| Security | Security compliance | No hardcoded secrets |
| Compatibility | API compatibility | No breaking changes |

## Validation Rules

### Determinism
All operations must produce identical outputs given identical inputs.

### Performance Constraints
- Request payload ‚â§ 64KB
- Response time ‚â§ 750ms
- Rate limit ~1 rps/client

### API Stability
Public APIs must maintain backward compatibility unless major version is incremented.

## Schema Evolution

Schemas follow semantic versioning:
- **PATCH**: Bug fixes, clarifications
- **MINOR**: New optional fields, backward-compatible additions
- **MAJOR**: Breaking changes, required field changes

---

*This documentation is automatically generated from CUE schema definitions.*
`;
}

// Generate assembly documentation from arbiter.assembly.cue
async function generateAssemblyDocumentation() {
  const timestamp = new Date().toISOString();
  let assemblyContent = '';
  
  try {
    // Try to read the assembly file
    assemblyContent = await fs.readFile('arbiter.assembly.cue', 'utf-8');
  } catch (error) {
    console.log(chalk.yellow('‚ö†Ô∏è No arbiter.assembly.cue found, generating template documentation'));
  }
  
  // Parse basic information from assembly file
  const kindMatch = assemblyContent.match(/kind:\s*"([^"]+)"/);
  const nameMatch = assemblyContent.match(/name:\s*"([^"]+)"/);
  const languageMatch = assemblyContent.match(/language:\s*"([^"]+)"/);
  const toolMatch = assemblyContent.match(/tool:\s*"([^"]+)"/);
  
  const kind = kindMatch?.[1] || 'unknown';
  const name = nameMatch?.[1] || 'unnamed-project';
  const language = languageMatch?.[1] || 'unknown';
  const tool = toolMatch?.[1] || 'unknown';
  
  return `# ${name} - Assembly Documentation

**Generated:** ${timestamp}  
**Artifact Type:** ${kind}  
**Primary Language:** ${language}  
**Build Tool:** ${tool}

## Project Overview

This document describes the Arbiter assembly configuration for the ${name} project.

## Artifact Configuration

### Type: ${kind}

${getArtifactDescription(kind)}

### Build Configuration

- **Build Tool:** ${tool}
- **Language:** ${language}
- **Targets:** ${assemblyContent.includes('targets:') ? 'Defined in assembly' : 'Default patterns'}

${assemblyContent.includes('outputs:') ? '- **Outputs:** Custom output specifications defined' : ''}

## Profile Configuration

${getProfileDescription(kind, assemblyContent)}

## Quality Gates

The following quality gates are enforced:

${getQualityGates(assemblyContent)}

## Schema Definitions

${getSchemaDefinitions(assemblyContent)}

## Validation Rules

- **Determinism:** ${assemblyContent.includes('determinism: true') ? 'Required - same inputs produce identical outputs' : 'Not explicitly required'}
- **API Compatibility:** ${assemblyContent.includes('forbidBreaking: true') ? 'Breaking changes forbidden' : 'No explicit API compatibility rules'}

## Development Workflow

1. **Validation:** Run \`arbiter check\` to validate assembly
2. **Surface Analysis:** Run \`arbiter surface ${language}\` to extract API surface  
3. **Testing:** Run \`arbiter tests generate\` to create test scaffolding
4. **Watch Mode:** Run \`arbiter watch\` for continuous validation

## Generated Files

This assembly configuration generates the following artifacts:

${getGeneratedFiles(assemblyContent, kind)}

---

*This documentation is automatically generated from \`arbiter.assembly.cue\`.*
`;
}

// Helper function to describe artifact types
function getArtifactDescription(kind) {
  const descriptions = {
    'library': 'A reusable library or package that can be imported by other projects.',
    'service': 'A standalone service or microservice with API endpoints.',
    'cli': 'A command-line interface tool or application.',
    'policy_bundle': 'A policy bundle containing security and governance rules.',
    'job': 'A batch job or scheduled task.',
    'unknown': 'Artifact type not specified in assembly configuration.'
  };
  return descriptions[kind] || descriptions['unknown'];
}

// Helper function to describe profile configuration
function getProfileDescription(kind, content) {
  if (content.includes('subjects:')) {
    return `### Policy Profile Configuration

This project uses a policy-specific profile with:
- NATS subject patterns for message routing
- Security derivation rules for sandbox profiles
- Policy compilation and validation requirements`;
  }
  
  if (content.includes('endpoints:')) {
    return `### Service Profile Configuration

This project uses a service profile with:
- HTTP endpoint definitions
- Health check configuration
- Service-specific validation rules`;
  }
  
  return `### ${kind.charAt(0).toUpperCase() + kind.slice(1)} Profile

Standard ${kind} profile with default validation and quality gates.`;
}

// Helper function to extract quality gates
function getQualityGates(content) {
  const gates = [];
  
  if (content.includes('cue_eval_passes: true')) {
    gates.push('- **CUE Evaluation:** All CUE expressions must evaluate successfully');
  }
  if (content.includes('policy_digest_deterministic: true')) {
    gates.push('- **Policy Determinism:** Policy compilation must be deterministic');
  }
  if (content.includes('bundle_completeness:')) {
    gates.push('- **Bundle Completeness:** All required policy components must be present');
  }
  if (content.includes('testCoverage:')) {
    const match = content.match(/testCoverage:\s*(\d+)/);
    gates.push(`- **Test Coverage:** Minimum ${match?.[1] || '90'}% coverage required`);
  }
  if (content.includes('lintPassing: true')) {
    gates.push('- **Linting:** All linting rules must pass');
  }
  if (content.includes('typeCheck: true')) {
    gates.push('- **Type Checking:** Static type analysis must pass');
  }
  
  return gates.length > 0 ? gates.join('\n') : '- No specific quality gates configured';
}

// Helper function to extract schema definitions
function getSchemaDefinitions(content) {
  if (content.includes('AtomCapability:')) {
    return `### Policy Schema Definitions

This project defines custom policy schemas:

#### AtomCapability
Defines atomic capabilities with effects, scope, and resource limits.

#### Macro  
Defines reusable macro templates that reference atom capabilities.

#### Playbook
Defines sequences of macro execution steps with guards and conditions.

#### Bundle
Defines complete policy bundles with atoms, macros, playbooks, and derivation rules.`;
  }
  
  return 'No custom schema definitions found in assembly.';
}

// Helper function to list generated files
function getGeneratedFiles(content, kind) {
  const files = [];
  
  if (content.includes('outputs:')) {
    const outputMatches = content.match(/outputs:\s*\[([\s\S]*?)\]/);
    if (outputMatches) {
      const outputs = outputMatches[1].split(',').map(s => s.trim().replace(/"/g, ''));
      files.push(...outputs.map(f => `- \`${f}\``));
    }
  }
  
  // Default files based on kind
  switch (kind) {
    case 'policy_bundle':
      if (files.length === 0) {
        files.push(
          '- `build/policy/bundles/policy_bundle.json`',
          '- `build/policy/sandbox_profiles/*.json`', 
          '- `build/policy/policy_digest.txt`'
        );
      }
      break;
    case 'library':
      files.push('- `dist/index.js` (or equivalent)', '- `dist/api-surface.json`');
      break;
    case 'service':
      files.push('- Service executable', '- API documentation', '- Health check endpoints');
      break;
    default:
      files.push('- Build artifacts as specified in assembly configuration');
  }
  
  return files.join('\n');
}

async function examplesCommand(type, options) {
  console.log(chalk.blue('üéØ Examples command'));
  console.log(chalk.yellow('üìã Example generation not yet implemented'));
  console.log(chalk.gray('This will generate example projects'));
  return 0;
}

async function explainCommand(options) {
  console.log(chalk.blue('üí¨ Explaining assembly configuration...'));
  
  try {
    // Read assembly file
    let assemblyContent = '';
    try {
      assemblyContent = await fs.readFile('arbiter.assembly.cue', 'utf-8');
      console.log(chalk.green('‚úÖ Found arbiter.assembly.cue'));
    } catch (error) {
      console.log(chalk.yellow('‚ö†Ô∏è No arbiter.assembly.cue found'));
      console.log(chalk.gray('Run: arbiter generate --template <type> to create one'));
      return 1;
    }

    // Parse and explain the assembly
    const explanation = parseAndExplainAssembly(assemblyContent);
    
    // Output explanation
    if (options.agentMode) {
      console.log(JSON.stringify({
        phase: 'assembly_explanation',
        explanation: explanation.structured,
        plainEnglish: explanation.plainEnglish,
        success: true
      }));
    } else {
      console.log('\n' + chalk.cyan('üìã Assembly Explanation:'));
      console.log(explanation.plainEnglish);
      
      console.log('\n' + chalk.cyan('üîß Technical Details:'));
      console.log(JSON.stringify(explanation.structured, null, 2));
    }

    return 0;
  } catch (error) {
    console.error(chalk.red('‚ùå Explanation failed:'), error.message);
    
    if (options.agentMode) {
      console.log(JSON.stringify({
        phase: 'assembly_explanation',
        error: error.message,
        success: false
      }));
    }
    
    return 1;
  }
}

// Parse and explain assembly configuration in plain English
function parseAndExplainAssembly(content) {
  const analysis = {
    kind: null,
    name: null,
    language: null,
    buildTool: null,
    hasSchemas: false,
    hasProfiles: false,
    hasValidation: false,
    features: []
  };

  // Extract basic information
  const kindMatch = content.match(/kind:\s*"([^"]+)"/);
  const nameMatch = content.match(/name:\s*"([^"]+)"/);
  const languageMatch = content.match(/language:\s*"([^"]+)"/);
  const toolMatch = content.match(/tool:\s*"([^"]+)"/);

  analysis.kind = kindMatch?.[1] || 'unknown';
  analysis.name = nameMatch?.[1] || 'unnamed-project';
  analysis.language = languageMatch?.[1] || 'unknown';
  analysis.buildTool = toolMatch?.[1] || 'unknown';

  // Detect features
  if (content.includes('schemas:')) {
    analysis.hasSchemas = true;
    analysis.features.push('custom schemas');
  }
  
  if (content.includes('Profile:')) {
    analysis.hasProfiles = true;
    analysis.features.push('profile configuration');
  }
  
  if (content.includes('validation:')) {
    analysis.hasValidation = true;
    analysis.features.push('validation rules');
  }

  if (content.includes('AtomCapability:')) {
    analysis.features.push('atom capability definitions');
  }

  if (content.includes('Macro:')) {
    analysis.features.push('macro templates');
  }

  if (content.includes('Playbook:')) {
    analysis.features.push('playbook workflows');
  }

  if (content.includes('subjects:')) {
    analysis.features.push('NATS subject patterns');
  }

  if (content.includes('derivations:')) {
    analysis.features.push('security derivations');
  }

  // Generate plain English explanation
  let explanation = `This is a ${analysis.kind} project`;
  
  if (analysis.name !== 'unnamed-project') {
    explanation += ` called "${analysis.name}"`;
  }
  
  explanation += ` written in ${analysis.language} and built with ${analysis.buildTool}.`;

  if (analysis.features.length > 0) {
    explanation += `\n\nKey features:\n`;
    analysis.features.forEach(feature => {
      explanation += `‚Ä¢ ${feature.charAt(0).toUpperCase() + feature.slice(1)}\n`;
    });
  }

  // Add specific explanations based on kind
  if (analysis.kind === 'policy_bundle') {
    explanation += `\nThis policy bundle defines security and governance rules using a three-tier architecture:
‚Ä¢ Atoms: Low-level capabilities with specific effects and resource limits
‚Ä¢ Macros: Reusable templates that configure atoms with parameters  
‚Ä¢ Playbooks: Workflows that orchestrate multiple macros with conditional logic

The system supports different execution modes (strict, explore, shadow) and generates sandbox profiles for secure execution.`;
  } else if (analysis.kind === 'service') {
    explanation += `\nThis service includes API endpoints, health checks, and service-specific validation rules. It's designed to run as a standalone microservice.`;
  } else if (analysis.kind === 'library') {
    explanation += `\nThis library provides reusable functionality that can be imported by other projects. It includes API surface tracking and compatibility checks.`;
  }

  if (analysis.hasValidation) {
    explanation += `\n\nQuality gates are configured to ensure code quality, performance, and compliance requirements are met before deployment.`;
  }

  return {
    plainEnglish: explanation,
    structured: analysis
  };
}

// Requirements analysis command
async function requirementsCommand(subcommand, inputFile, options) {
  if (subcommand !== 'analyze') {
    console.error(chalk.red('‚ùå Subcommand required'));
    console.log(chalk.gray('Usage: arbiter requirements analyze <file> --out <output>'));
    return 1;
  }

  if (!inputFile) {
    console.error(chalk.red('‚ùå Input file required'));
    console.log(chalk.gray('Usage: arbiter requirements analyze <file> --out <output>'));
    return 1;
  }

  console.log(chalk.blue('üîç Analyzing requirements...'));
  console.log(chalk.gray(`Input: ${inputFile}`));

  try {
    // Check if input file exists
    await fs.access(inputFile);
    
    // Read and parse markdown file
    const content = await fs.readFile(inputFile, 'utf-8');
    console.log(chalk.green('‚úÖ File read successfully'));

    // Parse markdown into structured requirements
    const requirements = parseMarkdownRequirements(content);
    console.log(chalk.green(`‚úÖ Parsed ${requirements.length} requirement groups`));

    // Generate CUE output
    const cueOutput = generateRequirementsCUE(requirements);
    
    // Write output file
    const outputFile = options.out || 'requirements.cue';
    await fs.writeFile(outputFile, cueOutput);
    console.log(chalk.green(`‚úÖ Written to ${outputFile}`));

    // Agent mode output
    if (options.agentMode) {
      console.log(JSON.stringify({
        phase: 'requirements_analysis',
        input: inputFile,
        output: outputFile,
        requirements: requirements.length,
        success: true
      }));
    }

    return 0;
  } catch (error) {
    console.error(chalk.red('‚ùå Requirements analysis failed:'), error.message);
    
    if (options.agentMode) {
      console.log(JSON.stringify({
        phase: 'requirements_analysis',
        input: inputFile,
        error: error.message,
        success: false
      }));
    }
    
    return 1;
  }
}

// Parse markdown content into structured requirements
function parseMarkdownRequirements(content) {
  const requirements = [];
  const lines = content.split('\n');
  let currentGroup = null;
  let currentRequirement = null;
  let reqCounter = 1;

  for (let i = 0; i < lines.length; i++) {
    const line = lines[i].trim();
    
    // Parse headers as requirement groups
    if (line.match(/^#{1,3}\s+(.+)/)) {
      const title = line.replace(/^#{1,3}\s+/, '');
      const slug = title.toLowerCase().replace(/[^a-z0-9]+/g, '-').replace(/^-|-$/g, '');
      
      currentGroup = {
        id: `GROUP-${slug}`,
        title,
        description: '',
        requirements: []
      };
      requirements.push(currentGroup);
      currentRequirement = null;
    }
    
    // Parse bullets as individual requirements
    else if (line.match(/^[-*]\s+(.+)/) && currentGroup) {
      const desc = line.replace(/^[-*]\s+/, '');
      const slug = desc.toLowerCase().replace(/[^a-z0-9]+/g, '-').replace(/^-|-$/g, '').substring(0, 20);
      
      // Extract tags from description
      const milestone = desc.match(/Milestone:\s*([^\s,]+)/i)?.[1] || 'M1';
      const deliverable = desc.includes('Deliverable:');
      const gate = desc.includes('Gate:');
      const risk = desc.includes('Risk:');
      
      currentRequirement = {
        id: `REQ-${slug}-${reqCounter.toString().padStart(2, '0')}`,
        title: desc.split('.')[0] || desc.substring(0, 50),
        description: desc,
        milestone,
        deliverable,
        gate,
        risk,
        acceptance: []
      };
      
      currentGroup.requirements.push(currentRequirement);
      reqCounter++;
    }
    
    // Parse sub-bullets as acceptance criteria
    else if (line.match(/^\s+[-*]\s+(.+)/) && currentRequirement) {
      const acceptance = line.replace(/^\s+[-*]\s+/, '');
      currentRequirement.acceptance.push(acceptance);
    }
  }

  return requirements;
}

// Generate CUE output from parsed requirements
function generateRequirementsCUE(requirements) {
  const timestamp = new Date().toISOString();
  
  let cue = `// Generated requirements from markdown analysis
// Timestamp: ${timestamp}
// API Version: arbiter.dev/v2

package requirements

apiVersion: "arbiter.dev/v2"
kind: "Requirements"
metadata: {
    name: "parsed-requirements"
    generated: "${timestamp}"
    source: "markdown-analysis"
}

requirements: {
`;

  for (const group of requirements) {
    cue += `    "${group.id}": {
        title: "${group.title.replace(/"/g, '\\"')}"
        description: "${group.description.replace(/"/g, '\\"')}"
        requirements: {
`;
    
    for (const req of group.requirements) {
      cue += `            "${req.id}": {
                title: "${req.title.replace(/"/g, '\\"')}"
                description: "${req.description.replace(/"/g, '\\"')}"
                milestone: "${req.milestone}"
                deliverable: ${req.deliverable}
                gate: ${req.gate}
                risk: ${req.risk}
                acceptance: [
`;
      
      for (const acceptance of req.acceptance) {
        cue += `                    "${acceptance.replace(/"/g, '\\"')}",
`;
      }
      
      cue += `                ]
            }
`;
    }
    
    cue += `        }
    }
`;
  }

  cue += `}

// Summary statistics
stats: {
    total_groups: ${requirements.length}
    total_requirements: ${requirements.reduce((sum, group) => sum + group.requirements.length, 0)}
    by_milestone: {
        M1: ${requirements.reduce((sum, group) => sum + group.requirements.filter(r => r.milestone === 'M1').length, 0)}
        M2: ${requirements.reduce((sum, group) => sum + group.requirements.filter(r => r.milestone === 'M2').length, 0)}
        M3: ${requirements.reduce((sum, group) => sum + group.requirements.filter(r => r.milestone === 'M3').length, 0)}
        M4: ${requirements.reduce((sum, group) => sum + group.requirements.filter(r => r.milestone === 'M4').length, 0)}
        M5: ${requirements.reduce((sum, group) => sum + group.requirements.filter(r => r.milestone === 'M5').length, 0)}
    }
}
`;

  return cue;
}

// Spec generation command
async function specCommand(subcommand, options) {
  if (subcommand !== 'generate') {
    console.error(chalk.red('‚ùå Subcommand required'));
    console.log(chalk.gray('Usage: arbiter spec generate --from-requirements <file> --template <type> --out <output>'));
    return 1;
  }

  console.log(chalk.blue('üõ†Ô∏è Generating specification...'));

  try {
    const requirementsFile = options.fromRequirements;
    const template = options.template || 'library';
    const outputFile = options.out || 'arbiter.assembly.cue';

    if (!requirementsFile) {
      console.error(chalk.red('‚ùå Requirements file required'));
      console.log(chalk.gray('Usage: --from-requirements <file>'));
      return 1;
    }

    // Check if requirements file exists
    await fs.access(requirementsFile);
    console.log(chalk.green(`‚úÖ Found requirements file: ${requirementsFile}`));

    // Read requirements (for now, we'll generate a basic spec)
    const requirementsContent = await fs.readFile(requirementsFile, 'utf-8');
    console.log(chalk.green('‚úÖ Requirements loaded'));

    // Generate assembly spec from requirements and template
    const assemblySpec = generateAssemblySpec(requirementsContent, template);
    
    // Write output
    await fs.writeFile(outputFile, assemblySpec);
    console.log(chalk.green(`‚úÖ Generated ${outputFile}`));

    // Agent mode output
    if (options.agentMode) {
      console.log(JSON.stringify({
        phase: 'spec_generation',
        input: requirementsFile,
        template,
        output: outputFile,
        success: true
      }));
    }

    return 0;
  } catch (error) {
    console.error(chalk.red('‚ùå Spec generation failed:'), error.message);
    
    if (options.agentMode) {
      console.log(JSON.stringify({
        phase: 'spec_generation',
        error: error.message,
        success: false
      }));
    }
    
    return 1;
  }
}

// Generate assembly specification from requirements and template
function generateAssemblySpec(requirementsContent, template) {
  const timestamp = new Date().toISOString();
  
  return `// Arbiter Assembly Specification
// Generated from requirements analysis
// Template: ${template}
// Generated: ${timestamp}

package assembly

import "github.com/arbiter-framework/schemas/artifact"
import "github.com/arbiter-framework/schemas/profiles"

// Metadata
apiVersion: "arbiter.dev/v2"
kind: "Assembly"
metadata: {
    name: "generated-assembly"
    template: "${template}"
    generated: "${timestamp}"
    source: "requirements-driven"
}

// Project artifact definition
Artifact: artifact.#Artifact & {
    kind: "${template}"
    language: "typescript" // TODO: detect from project
    
    build: {
        tool: "bun" // TODO: detect from project
        targets: ["./..."]
        matrix: {
            versions: ["latest"]
            os: ["linux", "darwin"] 
            arch: ["amd64", "arm64"]
        }
    }
    
    packaging: {
        publish: true
        registry: "npm" // TODO: detect from project
        artifact: "npm"
    }
}

// Profile configuration based on template
Profile: profiles.#${template} & {
    semver: "strict"
    apiSurface: {
        source: "generated"
        file: "./dist/api-surface.json"
    }
    contracts: {
        forbidBreaking: true
        invariants: [
            // TODO: Generate from requirements
            {
                name: "determinism"
                description: "Operations must be deterministic"
                rule: "same inputs produce identical outputs"
            },
            {
                name: "performance"
                description: "Respect performance constraints"
                rule: "response time <= 750ms, payload <= 64KB"
            }
        ]
    }
    gates: {
        quality: {
            testCoverage: 90
            lintPassing: true
            typeCheck: true
        }
        performance: {
            responseTime: "750ms"
            payloadSize: "64KB"
        }
    }
}

// Generated milestones (TODO: extract from requirements)
milestones: {
    M1: {
        title: "Core Foundation"
        description: "Basic functionality and infrastructure"
        deliverables: ["REQ-SERVER-01", "REQ-CLI-01"]
    }
    M2: {
        title: "Requirements Pipeline"
        description: "Requirements analysis and spec generation"
        deliverables: ["REQ-PIPELINE-01"]
        dependencies: ["M1"]
    }
}

// Quality contracts
contracts: {
    invariants: [
        {
            name: "api_stability"
            description: "Public APIs maintain backward compatibility"
            enforcement: "breaking_changes_require_major_version"
        },
        {
            name: "deterministic_outputs"
            description: "Same inputs produce identical outputs"
            enforcement: "validate_with_golden_files"
        }
    ]
}
`;
}

async function previewCommand(options) {
  console.log(chalk.blue('üëÅÔ∏è  Preview command'));
  console.log(chalk.yellow('üìã Generation preview not yet implemented'));
  console.log(chalk.gray('This will show deterministic generation plans'));
  return 0;
}

// Run CLI
if (require.main === module) {
  main().then(code => process.exit(code));
}